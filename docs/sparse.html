<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>R (BGU course)</title>
  <meta name="description" content="Class notes for the R course at the BGU’s IE&amp;M dept.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="R (BGU course)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for the R course at the BGU’s IE&amp;M dept." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="R (BGU course)" />
  
  <meta name="twitter:description" content="Class notes for the R course at the BGU’s IE&amp;M dept." />
  

<meta name="author" content="Jonathan D. Rosenblatt">


<meta name="date" content="2017-10-30">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="hadley.html">
<link rel="next" href="memory.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R Course</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#notation-conventions"><i class="fa fa-check"></i><b>1.1</b> Notation Conventions</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#what-r"><i class="fa fa-check"></i><b>2.1</b> What is R?</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#ecosystem"><i class="fa fa-check"></i><b>2.2</b> The R Ecosystem</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#bibliographic-notes"><i class="fa fa-check"></i><b>2.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#practice-yourself"><i class="fa fa-check"></i><b>2.4</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>3</b> R Basics</a><ul>
<li class="chapter" data-level="3.1" data-path="basics.html"><a href="basics.html#file-types"><i class="fa fa-check"></i><b>3.1</b> File types</a></li>
<li class="chapter" data-level="3.2" data-path="basics.html"><a href="basics.html#simple-calculator"><i class="fa fa-check"></i><b>3.2</b> Simple calculator</a></li>
<li class="chapter" data-level="3.3" data-path="basics.html"><a href="basics.html#probability-calculator"><i class="fa fa-check"></i><b>3.3</b> Probability calculator</a></li>
<li class="chapter" data-level="3.4" data-path="basics.html"><a href="basics.html#getting-help"><i class="fa fa-check"></i><b>3.4</b> Getting Help</a></li>
<li class="chapter" data-level="3.5" data-path="basics.html"><a href="basics.html#variable-asignment"><i class="fa fa-check"></i><b>3.5</b> Variable Asignment</a></li>
<li class="chapter" data-level="3.6" data-path="basics.html"><a href="basics.html#missing"><i class="fa fa-check"></i><b>3.6</b> Missing</a></li>
<li class="chapter" data-level="3.7" data-path="basics.html"><a href="basics.html#piping"><i class="fa fa-check"></i><b>3.7</b> Piping</a></li>
<li class="chapter" data-level="3.8" data-path="basics.html"><a href="basics.html#vector-creation-and-manipulation"><i class="fa fa-check"></i><b>3.8</b> Vector Creation and Manipulation</a></li>
<li class="chapter" data-level="3.9" data-path="basics.html"><a href="basics.html#search-paths-and-packages"><i class="fa fa-check"></i><b>3.9</b> Search Paths and Packages</a></li>
<li class="chapter" data-level="3.10" data-path="basics.html"><a href="basics.html#simple-plotting"><i class="fa fa-check"></i><b>3.10</b> Simple Plotting</a></li>
<li class="chapter" data-level="3.11" data-path="basics.html"><a href="basics.html#object-types"><i class="fa fa-check"></i><b>3.11</b> Object Types</a></li>
<li class="chapter" data-level="3.12" data-path="basics.html"><a href="basics.html#data-frames"><i class="fa fa-check"></i><b>3.12</b> Data Frames</a></li>
<li class="chapter" data-level="3.13" data-path="basics.html"><a href="basics.html#exctraction"><i class="fa fa-check"></i><b>3.13</b> Exctraction</a></li>
<li class="chapter" data-level="3.14" data-path="basics.html"><a href="basics.html#non-data.frame-object-classes"><i class="fa fa-check"></i><b>3.14</b> Non data.frame object classes</a></li>
<li class="chapter" data-level="3.15" data-path="basics.html"><a href="basics.html#data-import-and-export"><i class="fa fa-check"></i><b>3.15</b> Data Import and Export</a><ul>
<li class="chapter" data-level="3.15.1" data-path="basics.html"><a href="basics.html#import-from-web"><i class="fa fa-check"></i><b>3.15.1</b> Import from WEB</a></li>
<li class="chapter" data-level="3.15.2" data-path="basics.html"><a href="basics.html#export-as-csv"><i class="fa fa-check"></i><b>3.15.2</b> Export as CSV</a></li>
<li class="chapter" data-level="3.15.3" data-path="basics.html"><a href="basics.html#export-non-csv-files"><i class="fa fa-check"></i><b>3.15.3</b> Export non-CSV files</a></li>
<li class="chapter" data-level="3.15.4" data-path="basics.html"><a href="basics.html#reading-from-text-files"><i class="fa fa-check"></i><b>3.15.4</b> Reading From Text Files</a></li>
<li class="chapter" data-level="3.15.5" data-path="basics.html"><a href="basics.html#writing-data-to-text-files"><i class="fa fa-check"></i><b>3.15.5</b> Writing Data to Text Files</a></li>
<li class="chapter" data-level="3.15.6" data-path="basics.html"><a href="basics.html#xlsx-files"><i class="fa fa-check"></i><b>3.15.6</b> .XLS(X) files</a></li>
<li class="chapter" data-level="3.15.7" data-path="basics.html"><a href="basics.html#massive-files"><i class="fa fa-check"></i><b>3.15.7</b> Massive files</a></li>
<li class="chapter" data-level="3.15.8" data-path="basics.html"><a href="basics.html#databases"><i class="fa fa-check"></i><b>3.15.8</b> Databases</a></li>
</ul></li>
<li class="chapter" data-level="3.16" data-path="basics.html"><a href="basics.html#functions"><i class="fa fa-check"></i><b>3.16</b> Functions</a></li>
<li class="chapter" data-level="3.17" data-path="basics.html"><a href="basics.html#looping"><i class="fa fa-check"></i><b>3.17</b> Looping</a></li>
<li class="chapter" data-level="3.18" data-path="basics.html"><a href="basics.html#apply"><i class="fa fa-check"></i><b>3.18</b> Apply</a></li>
<li class="chapter" data-level="3.19" data-path="basics.html"><a href="basics.html#recursion"><i class="fa fa-check"></i><b>3.19</b> Recursion</a></li>
<li class="chapter" data-level="3.20" data-path="basics.html"><a href="basics.html#dates-and-times"><i class="fa fa-check"></i><b>3.20</b> Dates and Times</a></li>
<li class="chapter" data-level="3.21" data-path="basics.html"><a href="basics.html#bibliographic-notes-1"><i class="fa fa-check"></i><b>3.21</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="3.22" data-path="basics.html"><a href="basics.html#practice-yourself-1"><i class="fa fa-check"></i><b>3.22</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>4</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="eda.html"><a href="eda.html#summary-statistics"><i class="fa fa-check"></i><b>4.1</b> Summary Statistics</a><ul>
<li class="chapter" data-level="4.1.1" data-path="eda.html"><a href="eda.html#categorical-data"><i class="fa fa-check"></i><b>4.1.1</b> Categorical Data</a></li>
<li class="chapter" data-level="4.1.2" data-path="eda.html"><a href="eda.html#continous-data"><i class="fa fa-check"></i><b>4.1.2</b> Continous Data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="eda.html"><a href="eda.html#visualization"><i class="fa fa-check"></i><b>4.2</b> Visualization</a><ul>
<li class="chapter" data-level="4.2.1" data-path="eda.html"><a href="eda.html#categorical-data-1"><i class="fa fa-check"></i><b>4.2.1</b> Categorical Data</a></li>
<li class="chapter" data-level="4.2.2" data-path="eda.html"><a href="eda.html#continuous-data"><i class="fa fa-check"></i><b>4.2.2</b> Continuous Data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="eda.html"><a href="eda.html#bibliographic-notes-2"><i class="fa fa-check"></i><b>4.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="4.4" data-path="eda.html"><a href="eda.html#practice-yourself-2"><i class="fa fa-check"></i><b>4.4</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>5</b> Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="lm.html"><a href="lm.html#problem-setup"><i class="fa fa-check"></i><b>5.1</b> Problem Setup</a></li>
<li class="chapter" data-level="5.2" data-path="lm.html"><a href="lm.html#ols-estimation-in-r"><i class="fa fa-check"></i><b>5.2</b> OLS Estimation in R</a></li>
<li class="chapter" data-level="5.3" data-path="lm.html"><a href="lm.html#inference"><i class="fa fa-check"></i><b>5.3</b> Inference</a><ul>
<li class="chapter" data-level="5.3.1" data-path="lm.html"><a href="lm.html#testing-a-hypothesis-on-a-single-coefficient"><i class="fa fa-check"></i><b>5.3.1</b> Testing a Hypothesis on a Single Coefficient</a></li>
<li class="chapter" data-level="5.3.2" data-path="lm.html"><a href="lm.html#constructing-a-confidence-interval-on-a-single-coefficient"><i class="fa fa-check"></i><b>5.3.2</b> Constructing a Confidence Interval on a Single Coefficient</a></li>
<li class="chapter" data-level="5.3.3" data-path="lm.html"><a href="lm.html#multiple-regression"><i class="fa fa-check"></i><b>5.3.3</b> Multiple Regression</a></li>
<li class="chapter" data-level="5.3.4" data-path="lm.html"><a href="lm.html#anova"><i class="fa fa-check"></i><b>5.3.4</b> ANOVA (*)</a></li>
<li class="chapter" data-level="5.3.5" data-path="lm.html"><a href="lm.html#testing-a-hypothesis-on-a-single-contrast-returning-to-the-model-without-interactions-lm.2."><i class="fa fa-check"></i><b>5.3.5</b> Testing a Hypothesis on a Single Contrast (*) Returning to the model without interactions, <code>lm.2</code>.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="lm.html"><a href="lm.html#bibliographic-notes-3"><i class="fa fa-check"></i><b>5.4</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="5.5" data-path="lm.html"><a href="lm.html#practice-yourself-3"><i class="fa fa-check"></i><b>5.5</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>6</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="6.1" data-path="glm.html"><a href="glm.html#problem-setup-1"><i class="fa fa-check"></i><b>6.1</b> Problem Setup</a></li>
<li class="chapter" data-level="6.2" data-path="glm.html"><a href="glm.html#logistic-regression"><i class="fa fa-check"></i><b>6.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="glm.html"><a href="glm.html#logistic-regression-with-r"><i class="fa fa-check"></i><b>6.2.1</b> Logistic Regression with R</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="glm.html"><a href="glm.html#poisson-regression"><i class="fa fa-check"></i><b>6.3</b> Poisson Regression</a></li>
<li class="chapter" data-level="6.4" data-path="glm.html"><a href="glm.html#extensions"><i class="fa fa-check"></i><b>6.4</b> Extensions</a></li>
<li class="chapter" data-level="6.5" data-path="glm.html"><a href="glm.html#bibliographic-notes-4"><i class="fa fa-check"></i><b>6.5</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="6.6" data-path="glm.html"><a href="glm.html#practice-yourself-4"><i class="fa fa-check"></i><b>6.6</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lme.html"><a href="lme.html"><i class="fa fa-check"></i><b>7</b> Linear Mixed Models</a><ul>
<li class="chapter" data-level="7.1" data-path="lme.html"><a href="lme.html#problem-setup-2"><i class="fa fa-check"></i><b>7.1</b> Problem Setup</a><ul>
<li class="chapter" data-level="7.1.1" data-path="lme.html"><a href="lme.html#relation-to-manova-manova-multivariate-analysis-of-variance-manova-deals-with-the-estimation-of-effect-on-vector-valued-outcomes.-put-differently-in-anova-the-response-y-is-univariate-in-manova-the-outcome-is-multivariate.-manova-is-useful-when-there-are-correlations-among-the-entries-of-y.-otherwise--one-may-simply-solve-many-anova-problems-instead-of-a-single-manova."><i class="fa fa-check"></i><b>7.1.1</b> Relation to MANOVA (*) {#manova} Multivariate analysis of variance (MANOVA) deals with the estimation of effect on vector valued outcomes. Put differently: in ANOVA the response, <span class="math inline">\(y\)</span>, is univariate In MANOVA, the outcome is multivariate. MANOVA is useful when there are correlations among the entries of <span class="math inline">\(y\)</span>. Otherwise- one may simply solve many ANOVA problems, instead of a single MANOVA.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="lme.html"><a href="lme.html#mixed-models-with-r"><i class="fa fa-check"></i><b>7.2</b> Mixed Models with R</a><ul>
<li class="chapter" data-level="7.2.1" data-path="lme.html"><a href="lme.html#a-single-random-effect"><i class="fa fa-check"></i><b>7.2.1</b> A Single Random Effect</a></li>
<li class="chapter" data-level="7.2.2" data-path="lme.html"><a href="lme.html#multiple-random-effects"><i class="fa fa-check"></i><b>7.2.2</b> Multiple Random Effects</a></li>
<li class="chapter" data-level="7.2.3" data-path="lme.html"><a href="lme.html#a-full-mixed-model"><i class="fa fa-check"></i><b>7.2.3</b> A Full Mixed-Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="lme.html"><a href="lme.html#the-variance-components-view"><i class="fa fa-check"></i><b>7.3</b> The Variance-Components View</a></li>
<li class="chapter" data-level="7.4" data-path="lme.html"><a href="lme.html#bibliographic-notes-5"><i class="fa fa-check"></i><b>7.4</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="7.5" data-path="lme.html"><a href="lme.html#practice-yourself-5"><i class="fa fa-check"></i><b>7.5</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="multivariate.html"><a href="multivariate.html"><i class="fa fa-check"></i><b>8</b> Multivariate Data Analysis</a><ul>
<li class="chapter" data-level="8.1" data-path="multivariate.html"><a href="multivariate.html#signal-detection"><i class="fa fa-check"></i><b>8.1</b> Signal Detection</a><ul>
<li class="chapter" data-level="8.1.1" data-path="multivariate.html"><a href="multivariate.html#signal-detection-with-r"><i class="fa fa-check"></i><b>8.1.1</b> Signal Detection with R</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="multivariate.html"><a href="multivariate.html#signal-counting"><i class="fa fa-check"></i><b>8.2</b> Signal Counting</a></li>
<li class="chapter" data-level="8.3" data-path="multivariate.html"><a href="multivariate.html#identification"><i class="fa fa-check"></i><b>8.3</b> Signal Identification</a><ul>
<li class="chapter" data-level="8.3.1" data-path="multivariate.html"><a href="multivariate.html#signal-identification-in-r"><i class="fa fa-check"></i><b>8.3.1</b> Signal Identification in R</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="multivariate.html"><a href="multivariate.html#signal-estimation"><i class="fa fa-check"></i><b>8.4</b> Signal Estimation (*)</a></li>
<li class="chapter" data-level="8.5" data-path="multivariate.html"><a href="multivariate.html#multivariate-regression"><i class="fa fa-check"></i><b>8.5</b> Multivariate Regression (*)</a><ul>
<li class="chapter" data-level="8.5.1" data-path="multivariate.html"><a href="multivariate.html#multivariate-regression-with-r"><i class="fa fa-check"></i><b>8.5.1</b> Multivariate Regression with R</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="multivariate.html"><a href="multivariate.html#graphical-models"><i class="fa fa-check"></i><b>8.6</b> Graphical Models (*)</a><ul>
<li class="chapter" data-level="8.6.1" data-path="multivariate.html"><a href="multivariate.html#graphical-models-in-r"><i class="fa fa-check"></i><b>8.6.1</b> Graphical Models in R</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="multivariate.html"><a href="multivariate.html#biblipgraphic-notes"><i class="fa fa-check"></i><b>8.7</b> Biblipgraphic Notes</a></li>
<li class="chapter" data-level="8.8" data-path="multivariate.html"><a href="multivariate.html#practice-yourself-6"><i class="fa fa-check"></i><b>8.8</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="supervised.html"><a href="supervised.html"><i class="fa fa-check"></i><b>9</b> Supervised Learning</a><ul>
<li class="chapter" data-level="9.1" data-path="supervised.html"><a href="supervised.html#problem-setup-3"><i class="fa fa-check"></i><b>9.1</b> Problem Setup</a><ul>
<li class="chapter" data-level="9.1.1" data-path="supervised.html"><a href="supervised.html#common-hypothesis-classes"><i class="fa fa-check"></i><b>9.1.1</b> Common Hypothesis Classes</a></li>
<li class="chapter" data-level="9.1.2" data-path="supervised.html"><a href="supervised.html#common-complexity-penalties"><i class="fa fa-check"></i><b>9.1.2</b> Common Complexity Penalties</a></li>
<li class="chapter" data-level="9.1.3" data-path="supervised.html"><a href="supervised.html#unbiased-risk-estimation"><i class="fa fa-check"></i><b>9.1.3</b> Unbiased Risk Estimation</a></li>
<li class="chapter" data-level="9.1.4" data-path="supervised.html"><a href="supervised.html#collecting-the-pieces"><i class="fa fa-check"></i><b>9.1.4</b> Collecting the Pieces</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="supervised.html"><a href="supervised.html#supervised-learning-in-r"><i class="fa fa-check"></i><b>9.2</b> Supervised Learning in R</a><ul>
<li class="chapter" data-level="9.2.1" data-path="supervised.html"><a href="supervised.html#least-squares"><i class="fa fa-check"></i><b>9.2.1</b> Linear Models with Least Squares Loss</a></li>
<li class="chapter" data-level="9.2.2" data-path="supervised.html"><a href="supervised.html#svm"><i class="fa fa-check"></i><b>9.2.2</b> SVM</a></li>
<li class="chapter" data-level="9.2.3" data-path="supervised.html"><a href="supervised.html#neural-nets"><i class="fa fa-check"></i><b>9.2.3</b> Neural Nets</a></li>
<li class="chapter" data-level="9.2.4" data-path="supervised.html"><a href="supervised.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>9.2.4</b> Classification and Regression Trees (CART)</a></li>
<li class="chapter" data-level="9.2.5" data-path="supervised.html"><a href="supervised.html#k-nearest-neighbour-knn"><i class="fa fa-check"></i><b>9.2.5</b> K-nearest neighbour (KNN)</a></li>
<li class="chapter" data-level="9.2.6" data-path="supervised.html"><a href="supervised.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>9.2.6</b> Linear Discriminant Analysis (LDA)</a></li>
<li class="chapter" data-level="9.2.7" data-path="supervised.html"><a href="supervised.html#naive-bayes"><i class="fa fa-check"></i><b>9.2.7</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="supervised.html"><a href="supervised.html#bibliographic-notes-6"><i class="fa fa-check"></i><b>9.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="9.4" data-path="supervised.html"><a href="supervised.html#practice-yourself-7"><i class="fa fa-check"></i><b>9.4</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="unsupervised.html"><a href="unsupervised.html"><i class="fa fa-check"></i><b>10</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="10.1" data-path="unsupervised.html"><a href="unsupervised.html#dim-reduce"><i class="fa fa-check"></i><b>10.1</b> Dimensionality Reduction</a><ul>
<li class="chapter" data-level="10.1.1" data-path="unsupervised.html"><a href="unsupervised.html#pca"><i class="fa fa-check"></i><b>10.1.1</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="10.1.2" data-path="unsupervised.html"><a href="unsupervised.html#dimensionality-reduction-preliminaries"><i class="fa fa-check"></i><b>10.1.2</b> Dimensionality Reduction Preliminaries</a></li>
<li class="chapter" data-level="10.1.3" data-path="unsupervised.html"><a href="unsupervised.html#latent-variable-generative-approaches"><i class="fa fa-check"></i><b>10.1.3</b> Latent Variable Generative Approaches</a></li>
<li class="chapter" data-level="10.1.4" data-path="unsupervised.html"><a href="unsupervised.html#purely-algorithmic-approaches"><i class="fa fa-check"></i><b>10.1.4</b> Purely Algorithmic Approaches</a></li>
<li class="chapter" data-level="10.1.5" data-path="unsupervised.html"><a href="unsupervised.html#dimensionality-reduction-in-r"><i class="fa fa-check"></i><b>10.1.5</b> Dimensionality Reduction in R</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="unsupervised.html"><a href="unsupervised.html#cluster"><i class="fa fa-check"></i><b>10.2</b> Clustering</a><ul>
<li class="chapter" data-level="10.2.1" data-path="unsupervised.html"><a href="unsupervised.html#latent-variable-generative-approaches-1"><i class="fa fa-check"></i><b>10.2.1</b> Latent Variable Generative Approaches</a></li>
<li class="chapter" data-level="10.2.2" data-path="unsupervised.html"><a href="unsupervised.html#purely-algorithmic-approaches-1"><i class="fa fa-check"></i><b>10.2.2</b> Purely Algorithmic Approaches</a></li>
<li class="chapter" data-level="10.2.3" data-path="unsupervised.html"><a href="unsupervised.html#clustering-in-r"><i class="fa fa-check"></i><b>10.2.3</b> Clustering in R</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="unsupervised.html"><a href="unsupervised.html#bibliographic-notes-7"><i class="fa fa-check"></i><b>10.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="10.4" data-path="unsupervised.html"><a href="unsupervised.html#practice-yourself-8"><i class="fa fa-check"></i><b>10.4</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="plotting.html"><a href="plotting.html"><i class="fa fa-check"></i><b>11</b> Plotting</a><ul>
<li class="chapter" data-level="11.1" data-path="plotting.html"><a href="plotting.html#the-graphics-system"><i class="fa fa-check"></i><b>11.1</b> The graphics System</a><ul>
<li class="chapter" data-level="11.1.1" data-path="plotting.html"><a href="plotting.html#using-existing-plotting-functions"><i class="fa fa-check"></i><b>11.1.1</b> Using Existing Plotting Functions</a></li>
<li class="chapter" data-level="11.1.2" data-path="plotting.html"><a href="plotting.html#exporting-a-plot"><i class="fa fa-check"></i><b>11.1.2</b> Exporting a Plot</a></li>
<li class="chapter" data-level="11.1.3" data-path="plotting.html"><a href="plotting.html#fancy"><i class="fa fa-check"></i><b>11.1.3</b> Fancy graphics Examples</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="plotting.html"><a href="plotting.html#the-ggplot2-system"><i class="fa fa-check"></i><b>11.2</b> The ggplot2 System</a></li>
<li class="chapter" data-level="11.3" data-path="plotting.html"><a href="plotting.html#interactive-graphics"><i class="fa fa-check"></i><b>11.3</b> Interactive Graphics</a><ul>
<li class="chapter" data-level="11.3.1" data-path="plotting.html"><a href="plotting.html#plotly"><i class="fa fa-check"></i><b>11.3.1</b> Plotly</a></li>
<li class="chapter" data-level="11.3.2" data-path="plotting.html"><a href="plotting.html#html-widgets"><i class="fa fa-check"></i><b>11.3.2</b> HTML Widgets</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="plotting.html"><a href="plotting.html#bibliographic-notes-8"><i class="fa fa-check"></i><b>11.4</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="11.5" data-path="plotting.html"><a href="plotting.html#practice-yourself-9"><i class="fa fa-check"></i><b>11.5</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="report.html"><a href="report.html"><i class="fa fa-check"></i><b>12</b> Reports</a><ul>
<li class="chapter" data-level="12.1" data-path="report.html"><a href="report.html#knitr"><i class="fa fa-check"></i><b>12.1</b> knitr</a><ul>
<li class="chapter" data-level="12.1.1" data-path="report.html"><a href="report.html#installation"><i class="fa fa-check"></i><b>12.1.1</b> Installation</a></li>
<li class="chapter" data-level="12.1.2" data-path="report.html"><a href="report.html#pandoc-markdown"><i class="fa fa-check"></i><b>12.1.2</b> Pandoc Markdown</a></li>
<li class="chapter" data-level="12.1.3" data-path="report.html"><a href="report.html#rmarkdown"><i class="fa fa-check"></i><b>12.1.3</b> Rmarkdown</a></li>
<li class="chapter" data-level="12.1.4" data-path="report.html"><a href="report.html#compiling"><i class="fa fa-check"></i><b>12.1.4</b> Compiling</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="report.html"><a href="report.html#bookdown"><i class="fa fa-check"></i><b>12.2</b> bookdown</a></li>
<li class="chapter" data-level="12.3" data-path="report.html"><a href="report.html#shiny"><i class="fa fa-check"></i><b>12.3</b> Shiny</a><ul>
<li class="chapter" data-level="12.3.1" data-path="report.html"><a href="report.html#installation-1"><i class="fa fa-check"></i><b>12.3.1</b> Installation</a></li>
<li class="chapter" data-level="12.3.2" data-path="report.html"><a href="report.html#the-basics-of-shiny"><i class="fa fa-check"></i><b>12.3.2</b> The Basics of Shiny</a></li>
<li class="chapter" data-level="12.3.3" data-path="report.html"><a href="report.html#beyond-the-basics"><i class="fa fa-check"></i><b>12.3.3</b> Beyond the Basics</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="report.html"><a href="report.html#flexdashboard"><i class="fa fa-check"></i><b>12.4</b> Flexdashboard</a></li>
<li class="chapter" data-level="12.5" data-path="report.html"><a href="report.html#bibliographic-notes-9"><i class="fa fa-check"></i><b>12.5</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="12.6" data-path="report.html"><a href="report.html#practice-yourself-10"><i class="fa fa-check"></i><b>12.6</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="hadley.html"><a href="hadley.html"><i class="fa fa-check"></i><b>13</b> The Hadleyverse</a><ul>
<li class="chapter" data-level="13.1" data-path="hadley.html"><a href="hadley.html#readr"><i class="fa fa-check"></i><b>13.1</b> readr</a></li>
<li class="chapter" data-level="13.2" data-path="hadley.html"><a href="hadley.html#dplyr"><i class="fa fa-check"></i><b>13.2</b> dplyr</a></li>
<li class="chapter" data-level="13.3" data-path="hadley.html"><a href="hadley.html#tidyr"><i class="fa fa-check"></i><b>13.3</b> tidyr</a></li>
<li class="chapter" data-level="13.4" data-path="hadley.html"><a href="hadley.html#reshape2"><i class="fa fa-check"></i><b>13.4</b> reshape2</a></li>
<li class="chapter" data-level="13.5" data-path="hadley.html"><a href="hadley.html#stringr"><i class="fa fa-check"></i><b>13.5</b> stringr</a></li>
<li class="chapter" data-level="13.6" data-path="hadley.html"><a href="hadley.html#anytime"><i class="fa fa-check"></i><b>13.6</b> anytime</a></li>
<li class="chapter" data-level="13.7" data-path="hadley.html"><a href="hadley.html#biblipgraphic-notes-1"><i class="fa fa-check"></i><b>13.7</b> Biblipgraphic Notes</a></li>
<li class="chapter" data-level="13.8" data-path="hadley.html"><a href="hadley.html#practice-yourself-11"><i class="fa fa-check"></i><b>13.8</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="sparse.html"><a href="sparse.html"><i class="fa fa-check"></i><b>14</b> Sparse Representations</a><ul>
<li class="chapter" data-level="14.1" data-path="sparse.html"><a href="sparse.html#sparse-matrix-representations"><i class="fa fa-check"></i><b>14.1</b> Sparse Matrix Representations</a><ul>
<li class="chapter" data-level="14.1.1" data-path="sparse.html"><a href="sparse.html#coo"><i class="fa fa-check"></i><b>14.1.1</b> Coordinate List Representation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sparse.html"><a href="sparse.html#compressed-column-oriented-representation"><i class="fa fa-check"></i><b>14.1.2</b> Compressed Column Oriented Representation</a></li>
<li class="chapter" data-level="14.1.3" data-path="sparse.html"><a href="sparse.html#compressed-row-oriented-representation"><i class="fa fa-check"></i><b>14.1.3</b> Compressed Row Oriented Representation</a></li>
<li class="chapter" data-level="14.1.4" data-path="sparse.html"><a href="sparse.html#sparse-algorithms"><i class="fa fa-check"></i><b>14.1.4</b> Sparse Algorithms</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sparse.html"><a href="sparse.html#sparse-matrices-and-sparse-models-in-r"><i class="fa fa-check"></i><b>14.2</b> Sparse Matrices and Sparse Models in R</a><ul>
<li class="chapter" data-level="14.2.1" data-path="sparse.html"><a href="sparse.html#the-matrix-package"><i class="fa fa-check"></i><b>14.2.1</b> The Matrix Package</a></li>
<li class="chapter" data-level="14.2.2" data-path="sparse.html"><a href="sparse.html#the-glmnet-package"><i class="fa fa-check"></i><b>14.2.2</b> The glmnet Package</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="sparse.html"><a href="sparse.html#bibliographic-notes-10"><i class="fa fa-check"></i><b>14.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="14.4" data-path="sparse.html"><a href="sparse.html#practice-yourself-12"><i class="fa fa-check"></i><b>14.4</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="memory.html"><a href="memory.html"><i class="fa fa-check"></i><b>15</b> Memory Efficiency</a><ul>
<li class="chapter" data-level="15.1" data-path="memory.html"><a href="memory.html#efficient-computing-from-ram"><i class="fa fa-check"></i><b>15.1</b> Efficient Computing from RAM</a><ul>
<li class="chapter" data-level="15.1.1" data-path="memory.html"><a href="memory.html#summary-statistics-from-ram"><i class="fa fa-check"></i><b>15.1.1</b> Summary Statistics from RAM</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="memory.html"><a href="memory.html#computing-from-a-database"><i class="fa fa-check"></i><b>15.2</b> Computing from a Database</a></li>
<li class="chapter" data-level="15.3" data-path="memory.html"><a href="memory.html#file-structure"><i class="fa fa-check"></i><b>15.3</b> Computing From Efficient File Structrures</a><ul>
<li class="chapter" data-level="15.3.1" data-path="memory.html"><a href="memory.html#bigmemory"><i class="fa fa-check"></i><b>15.3.1</b> bigmemory</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="memory.html"><a href="memory.html#ff"><i class="fa fa-check"></i><b>15.4</b> ff</a><ul>
<li class="chapter" data-level="15.4.1" data-path="memory.html"><a href="memory.html#matter"><i class="fa fa-check"></i><b>15.4.1</b> matter</a></li>
<li class="chapter" data-level="15.4.2" data-path="memory.html"><a href="memory.html#iotools"><i class="fa fa-check"></i><b>15.4.2</b> iotools</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="memory.html"><a href="memory.html#computing-from-a-distributed-file-system"><i class="fa fa-check"></i><b>15.5</b> Computing from a Distributed File System</a></li>
<li class="chapter" data-level="15.6" data-path="memory.html"><a href="memory.html#bibliographic-notes-11"><i class="fa fa-check"></i><b>15.6</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="15.7" data-path="memory.html"><a href="memory.html#practice-yourself-13"><i class="fa fa-check"></i><b>15.7</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="parallel.html"><a href="parallel.html"><i class="fa fa-check"></i><b>16</b> Parallel Computing</a><ul>
<li class="chapter" data-level="16.1" data-path="parallel.html"><a href="parallel.html#implicit-parallelism"><i class="fa fa-check"></i><b>16.1</b> Implicit Parallelism</a></li>
<li class="chapter" data-level="16.2" data-path="parallel.html"><a href="parallel.html#explicit-parallelism"><i class="fa fa-check"></i><b>16.2</b> Explicit Parallelism</a><ul>
<li class="chapter" data-level="16.2.1" data-path="parallel.html"><a href="parallel.html#caution-implicit-with-explicit-parallelism"><i class="fa fa-check"></i><b>16.2.1</b> Caution: Implicit with Explicit Parallelism</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="parallel.html"><a href="parallel.html#bibliographic-notes-12"><i class="fa fa-check"></i><b>16.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="16.4" data-path="parallel.html"><a href="parallel.html#practice-yourself-14"><i class="fa fa-check"></i><b>16.4</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="algebra.html"><a href="algebra.html"><i class="fa fa-check"></i><b>17</b> Numerical Linear Algebra</a><ul>
<li class="chapter" data-level="17.1" data-path="algebra.html"><a href="algebra.html#lu-factorization"><i class="fa fa-check"></i><b>17.1</b> LU Factorization</a></li>
<li class="chapter" data-level="17.2" data-path="algebra.html"><a href="algebra.html#cholesky-factorization"><i class="fa fa-check"></i><b>17.2</b> Cholesky Factorization</a></li>
<li class="chapter" data-level="17.3" data-path="algebra.html"><a href="algebra.html#qr-factorization"><i class="fa fa-check"></i><b>17.3</b> QR Factorization</a></li>
<li class="chapter" data-level="17.4" data-path="algebra.html"><a href="algebra.html#singular-value-factorization"><i class="fa fa-check"></i><b>17.4</b> Singular Value Factorization</a></li>
<li class="chapter" data-level="17.5" data-path="algebra.html"><a href="algebra.html#iterative-methods"><i class="fa fa-check"></i><b>17.5</b> Iterative Methods</a></li>
<li class="chapter" data-level="17.6" data-path="algebra.html"><a href="algebra.html#solving-ols"><i class="fa fa-check"></i><b>17.6</b> Solving the OLS Problem</a></li>
<li class="chapter" data-level="17.7" data-path="algebra.html"><a href="algebra.html#bibliographic-notes-13"><i class="fa fa-check"></i><b>17.7</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="17.8" data-path="algebra.html"><a href="algebra.html#practice-yourself-15"><i class="fa fa-check"></i><b>17.8</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="convex.html"><a href="convex.html"><i class="fa fa-check"></i><b>18</b> Convex Optimization</a><ul>
<li class="chapter" data-level="18.1" data-path="convex.html"><a href="convex.html#bibliographic-notes-14"><i class="fa fa-check"></i><b>18.1</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="18.2" data-path="convex.html"><a href="convex.html#practice-yourself-16"><i class="fa fa-check"></i><b>18.2</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="rcpp.html"><a href="rcpp.html"><i class="fa fa-check"></i><b>19</b> RCpp</a><ul>
<li class="chapter" data-level="19.1" data-path="rcpp.html"><a href="rcpp.html#bibliographic-notes-15"><i class="fa fa-check"></i><b>19.1</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="19.2" data-path="rcpp.html"><a href="rcpp.html#practice-yourself-17"><i class="fa fa-check"></i><b>19.2</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="debugging.html"><a href="debugging.html"><i class="fa fa-check"></i><b>20</b> Debugging Tools</a><ul>
<li class="chapter" data-level="20.1" data-path="debugging.html"><a href="debugging.html#bibliographic-notes-16"><i class="fa fa-check"></i><b>20.1</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="20.2" data-path="debugging.html"><a href="debugging.html#practice-yourself-18"><i class="fa fa-check"></i><b>20.2</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="datatable.html"><a href="datatable.html"><i class="fa fa-check"></i><b>21</b> data.table</a><ul>
<li class="chapter" data-level="21.1" data-path="datatable.html"><a href="datatable.html#make-your-own-variables"><i class="fa fa-check"></i><b>21.1</b> Make your own variables</a></li>
<li class="chapter" data-level="21.2" data-path="datatable.html"><a href="datatable.html#join"><i class="fa fa-check"></i><b>21.2</b> Join</a></li>
<li class="chapter" data-level="21.3" data-path="datatable.html"><a href="datatable.html#reshaping-data"><i class="fa fa-check"></i><b>21.3</b> Reshaping data</a><ul>
<li class="chapter" data-level="21.3.1" data-path="datatable.html"><a href="datatable.html#wide-to-long"><i class="fa fa-check"></i><b>21.3.1</b> Wide to long</a></li>
<li class="chapter" data-level="21.3.2" data-path="datatable.html"><a href="datatable.html#long-to-wide"><i class="fa fa-check"></i><b>21.3.2</b> Long to wide</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="datatable.html"><a href="datatable.html#bibliographic-notes-17"><i class="fa fa-check"></i><b>21.4</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="21.5" data-path="datatable.html"><a href="datatable.html#practice-yourself-19"><i class="fa fa-check"></i><b>21.5</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="bib.html"><a href="bib.html"><i class="fa fa-check"></i><b>22</b> Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R (BGU course)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sparse" class="section level1">
<h1><span class="header-section-number">Chapter 14</span> Sparse Representations</h1>
<p>Analyzing “bigdata” in R is a challenge because the workspace is memory resident, i.e., all your objects are stored in RAM. As a rule of thumb, fitting models requires about 5 times the size of the data. This means that if you have 1 GB of data, you might need about 5 GB to fit a linear models. We will discuss how to compute <em>out of RAM</em> in the Memory Efficiency Chapter <a href="memory.html#memory">15</a>. In this chapter, we discuss efficient representations of your data, so that it takes less memory. The fundamental idea, is that if your data is <em>sparse</em>, i.e., there are many zero entries in your data, then a naive <code>data.frame</code> or <code>matrix</code> will consume memory for all these zeroes. If, however, you have many recurring zeroes, it is more efficient to save only the non-zero entries.</p>
<p>When we say <em>data</em>, we actually mean the <code>model.matrix</code>. The <code>model.matrix</code> is a matrix that R grows, converting all your factors to numeric variables that can be computed with. <em>Dummy coding</em> of your factors, for instance, is something that is done in your <code>model.matrix</code>. If you have a factor with many levels, you can imagine that after dummy coding it, many zeroes will be present.</p>
<p>The <strong>Matrix</strong> package replaces the <code>matrix</code> class, with several sparse representations of matrix objects.</p>
<p>When using sparse representation, and the <strong>Matrix</strong> package, you will need an implementation of your favorite model fitting algorithm (e.g. <code>lm</code>) that is adapted to these sparse representations; otherwise, R will cast the sparse matrix into a regular (non-sparse) matrix, and you will have saved nothing in RAM.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> If you are familiar with MATLAB you should know that one of the great capabilities of MATLAB, is the excellent treatment of sparse matrices with the <code>sparse</code> function.
</div>

<p>Before we go into details, here is a simple example. We will create a factor of letters with the <code>letters</code> function. Clearly, this factor can take only <span class="math inline">\(26\)</span> values. This means that <span class="math inline">\(25/26\)</span> of the <code>model.matrix</code> will be zeroes after dummy coding. We will compare the memory footprint of the naive <code>model.matrix</code> with the sparse representation of the same matrix.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(magrittr)
reps &lt;-<span class="st"> </span><span class="fl">1e6</span> <span class="co"># number of samples</span>
y&lt;-<span class="kw">rnorm</span>(reps)
x&lt;-<span class="st"> </span>letters <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">sample</span>(reps, <span class="dt">replace=</span><span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>factor</code></pre></div>
<p>The object <code>x</code> is a factor of letters:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(x)</code></pre></div>
<pre><code>## [1] n x z f a i
## Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z</code></pre>
<p>We dummy code <code>x</code> with the <code>model.matrix</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span>x<span class="op">-</span><span class="dv">1</span>)
<span class="kw">head</span>(X.<span class="dv">1</span>)</code></pre></div>
<pre><code>##   xa xb xc xd xe xf xg xh xi xj xk xl xm xn xo xp xq xr xs xt xu xv xw xx
## 1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0
## 2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1
## 3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## 4  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## 5  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
## 6  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
##   xy xz
## 1  0  0
## 2  0  0
## 3  0  1
## 4  0  0
## 5  0  0
## 6  0  0</code></pre>
<p>We call <strong>MatrixModels</strong> for an implementation of <code>model.matrix</code> that supports sparse representations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(MatrixModels))
X.<span class="dv">2</span>&lt;-<span class="st"> </span><span class="kw">as</span>(x,<span class="st">&quot;sparseMatrix&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>t <span class="co"># Makes sparse dummy model.matrix</span>
<span class="kw">head</span>(X.<span class="dv">2</span>)</code></pre></div>
<pre><code>## 6 x 26 sparse Matrix of class &quot;dgCMatrix&quot;</code></pre>
<pre><code>##    [[ suppressing 26 column names &#39;a&#39;, &#39;b&#39;, &#39;c&#39; ... ]]</code></pre>
<pre><code>##                                                         
## [1,] . . . . . . . . . . . . . 1 . . . . . . . . . . . .
## [2,] . . . . . . . . . . . . . . . . . . . . . . . 1 . .
## [3,] . . . . . . . . . . . . . . . . . . . . . . . . . 1
## [4,] . . . . . 1 . . . . . . . . . . . . . . . . . . . .
## [5,] 1 . . . . . . . . . . . . . . . . . . . . . . . . .
## [6,] . . . . . . . . 1 . . . . . . . . . . . . . . . . .</code></pre>
<p>Notice that the matrices have the same dimensions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(X.<span class="dv">1</span>)</code></pre></div>
<pre><code>## [1] 1000000      26</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(X.<span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 1000000      26</code></pre>
<p>The memory footprint of the matrices, given by the <code>pryr::object_size</code> function, are very very different.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pryr<span class="op">::</span><span class="kw">object_size</span>(X.<span class="dv">1</span>)</code></pre></div>
<pre><code>## 264 MB</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pryr<span class="op">::</span><span class="kw">object_size</span>(X.<span class="dv">2</span>)</code></pre></div>
<pre><code>## 12 MB</code></pre>
<p>Things to note:</p>
<ul>
<li>The sparse representation takes a whole lot less memory than the non sparse.</li>
<li>The <code>as(,&quot;sparseMatrix&quot;)</code> function grows the dummy variable representation of the factor <code>x</code>.</li>
<li>The <strong>pryr</strong> package provides many facilities for inspecting the memory footprint of your objects and code.</li>
</ul>
<p>With a sparse representation, we not only saved on RAM, but also on the computing time of fitting a model. Here is the timing of a non sparse representation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(lm.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>X.<span class="dv">1</span>)) </code></pre></div>
<pre><code>##    user  system elapsed 
##   3.828   0.120   3.946</code></pre>
<p>Well actually, <code>lm</code> is a wrapper for the <code>lm.fit</code> function. If we override all the overhead of <code>lm</code>, and call <code>lm.fit</code> directly, we gain some time:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(lm.<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">lm.fit</span>(<span class="dt">y=</span>y, <span class="dt">x=</span>X.<span class="dv">1</span>))</code></pre></div>
<pre><code>##    user  system elapsed 
##   1.080   0.008   1.088</code></pre>
<p>We now do the same with the sparse representation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system.time</span>(lm.<span class="dv">2</span> &lt;-<span class="st"> </span>MatrixModels<span class="op">:::</span><span class="kw">lm.fit.sparse</span>(X.<span class="dv">2</span>,y))</code></pre></div>
<pre><code>##    user  system elapsed 
##   0.208   0.012   0.224</code></pre>
<p>It is only left to verify that the returned coefficients are the same:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">all.equal</span>(lm.<span class="dv">2</span>, <span class="kw">unname</span>(lm.<span class="dv">1</span><span class="op">$</span>coefficients), <span class="dt">tolerance =</span> <span class="fl">1e-12</span>)</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>You can also visualize the non zero entries, i.e., the sparsity structure.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">image</span>(X.<span class="dv">2</span>[<span class="dv">1</span><span class="op">:</span><span class="dv">26</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">26</span>])</code></pre></div>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-275-1.png" width="50%" /></p>
<div id="sparse-matrix-representations" class="section level2">
<h2><span class="header-section-number">14.1</span> Sparse Matrix Representations</h2>
<p>We first distinguish between the two main goals of the efficient representation: (i) efficient writing, i.e., modification; (ii) efficient reading, i.e., access. For our purposes, we will typically want efficient reading, since the <code>model.matrix</code> will not change while a model is being fitted.</p>
<p>Representations designed for writing include the <em>dictionary of keys</em>, <em>list of lists</em>, and a <em>coordinate list</em>. Representations designed for efficient reading include the <em>compressed sparse row</em> and <em>compressed sparse column</em>.</p>
<div id="coo" class="section level3">
<h3><span class="header-section-number">14.1.1</span> Coordinate List Representation</h3>
<p>A <em>coordinate list representation</em>, also known as <em>COO</em>, or <em>triplet represantation</em> is simply a list of the non zero entries. Each element in the list is a triplet of the column, row, and value, of each non-zero entry in the matrix.</p>
</div>
<div id="compressed-column-oriented-representation" class="section level3">
<h3><span class="header-section-number">14.1.2</span> Compressed Column Oriented Representation</h3>
<p>A <em>compressed column oriented representation</em>, also known as <em>compressed sparse column</em>, or <em>CSC</em>, where the <strong>column</strong> index is similar to COO, but instead of saving the row indexes, we save the locations in the column index vectors where the row index has to increase. The following figure may clarify this simple idea.</p>
<div class="figure">
<img src="art/crc.png" alt="The CSC data structure. From Shah and Gilbert (2004). Remember that MATLAB is written in C, where the indexing starts at 0, and not 1." />
<p class="caption">The CSC data structure. From <span class="citation">Shah and Gilbert (<a href="#ref-shah2004sparse">2004</a>)</span>. Remember that MATLAB is written in C, where the indexing starts at <span class="math inline">\(0\)</span>, and not <span class="math inline">\(1\)</span>.</p>
</div>
<p>The nature of statistical applications is such, that CSC representation is typically the most economical, justifying its popularity.</p>
</div>
<div id="compressed-row-oriented-representation" class="section level3">
<h3><span class="header-section-number">14.1.3</span> Compressed Row Oriented Representation</h3>
<p>A <em>compressed row oriented representation</em>, also known as <em>compressed sparse row</em>, or <em>CSR</em>, is very similar to CSC, after switching the role of rows and columns. CSR is much less popular than CSC.</p>
</div>
<div id="sparse-algorithms" class="section level3">
<h3><span class="header-section-number">14.1.4</span> Sparse Algorithms</h3>
<p>We will go into the details of some algorithms in the Numerical Linear Algebra Chapter <a href="algebra.html#algebra">17</a>. For our current purposes two things need to be emphasized:</p>
<ol style="list-style-type: decimal">
<li><p>A mathematician may write <span class="math inline">\(Ax=b \Rightarrow x=A^{-1}b\)</span>. A computer, however, would <strong>never</strong> compute <span class="math inline">\(A^{-1}\)</span> in order to find <span class="math inline">\(x\)</span>, but rather use one of many endlessly many numerical algorithms.</p></li>
<li><p>Working with sparse representations requires using a function that is aware of the representation you are using.</p></li>
</ol>
</div>
</div>
<div id="sparse-matrices-and-sparse-models-in-r" class="section level2">
<h2><span class="header-section-number">14.2</span> Sparse Matrices and Sparse Models in R</h2>
<div id="the-matrix-package" class="section level3">
<h3><span class="header-section-number">14.2.1</span> The Matrix Package</h3>
<p>The <strong>Matrix</strong> package provides facilities to deal with real (stored as double precision), logical and so-called “pattern” (binary) dense and sparse matrices. There are provisions to provide integer and complex (stored as double precision complex) matrices.</p>
<p>The sparse matrix classes include:</p>
<ul>
<li><code>TsparseMatrix</code>: a virtual class of the various sparse matrices in triplet representation.</li>
<li><code>CsparseMatrix</code>: a virtual class of the various sparse matrices in CSC representation.</li>
<li><code>RsparseMatrix</code>: a virtual class of the various sparse matrices in CSR representation.</li>
</ul>
<p>For matrices of real numbers, stored in <em>double precision</em>, the <strong>Matrix</strong> package provides the following (non virtual) classes:</p>
<ul>
<li><code>dgTMatrix</code>: a <strong>general</strong> sparse matrix of <strong>doubles</strong>, in <strong>triplet</strong> representation.</li>
<li><code>dgCMatrix</code>: a <strong>general</strong> sparse matrix of <strong>doubles</strong>, in <strong>CSC</strong> representation.</li>
<li><code>dsCMatrix</code>: a <strong>symmetric</strong> sparse matrix of <strong>doubles</strong>, in <strong>CSC</strong> representation.</li>
<li><code>dtCMatrix</code>: a <strong>triangular</strong> sparse matrix of <strong>doubles</strong>, in <strong>CSC</strong> representation.</li>
</ul>
<p>Why bother with distinguishing between the different shapes of the matrix? Because the more structure is assumed on a matrix, the more our (statistical) algorithms can be optimized. For our purposes <code>dgCMatrix</code> will be the most useful.</p>
</div>
<div id="the-glmnet-package" class="section level3">
<h3><span class="header-section-number">14.2.2</span> The glmnet Package</h3>
<p>As previously stated, an efficient storage of the <code>model.matrix</code> is half of the story. We now need implementations of our favorite statistical algorithms that make use of this representation. At the time of writing, a very useful package that does that is the <strong>glmnet</strong> package, which allows to fit linear models, generalized linear models, with ridge, lasso, and elastic net regularization. The <strong>glmnet</strong> package allows all of this, using the sparse matrices of the <strong>Matrix</strong> package.</p>
<p>The following example is taken from <a href="http://www.johnmyleswhite.com/notebook/2011/10/31/using-sparse-matrices-in-r/">John Myles White’s blog</a>, and compares the runtime of fitting an OLS model, using <code>glmnet</code> with both sparse and dense matrix representations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(<span class="st">&#39;glmnet&#39;</span>))

<span class="kw">set.seed</span>(<span class="dv">1</span>)
performance &lt;-<span class="st"> </span><span class="kw">data.frame</span>()
 
<span class="cf">for</span> (sim <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>){
  n &lt;-<span class="st"> </span><span class="dv">10000</span>
  p &lt;-<span class="st"> </span><span class="dv">500</span>
 
  nzc &lt;-<span class="st"> </span><span class="kw">trunc</span>(p <span class="op">/</span><span class="st"> </span><span class="dv">10</span>)
 
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n <span class="op">*</span><span class="st"> </span>p), n, p) <span class="co">#make a dense matrix</span>
  iz &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span>(n <span class="op">*</span><span class="st"> </span>p),
               <span class="dt">size =</span> n <span class="op">*</span><span class="st"> </span>p <span class="op">*</span><span class="st"> </span><span class="fl">0.85</span>,
               <span class="dt">replace =</span> <span class="ot">FALSE</span>)
  x[iz] &lt;-<span class="st"> </span><span class="dv">0</span> <span class="co"># sparsify by injecting zeroes</span>
  sx &lt;-<span class="st"> </span><span class="kw">Matrix</span>(x, <span class="dt">sparse =</span> <span class="ot">TRUE</span>) <span class="co"># save as a sparse object</span>
 
  beta &lt;-<span class="st"> </span><span class="kw">rnorm</span>(nzc)
  fx &lt;-<span class="st"> </span>x[, <span class="kw">seq</span>(nzc)] <span class="op">%*%</span><span class="st"> </span>beta
 
  eps &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n)
  y &lt;-<span class="st"> </span>fx <span class="op">+</span><span class="st"> </span>eps <span class="co"># make data</span>
 
  <span class="co"># Now to the actual model fitting:</span>
  sparse.times &lt;-<span class="st"> </span><span class="kw">system.time</span>(fit1 &lt;-<span class="st"> </span><span class="kw">glmnet</span>(sx, y)) <span class="co"># sparse glmnet</span>
  full.times &lt;-<span class="st"> </span><span class="kw">system.time</span>(fit2 &lt;-<span class="st"> </span><span class="kw">glmnet</span>(x, y)) <span class="co"># dense glmnet</span>
  
  sparse.size &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">object.size</span>(sx))
  full.size &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">object.size</span>(x))
 
  performance &lt;-<span class="st"> </span><span class="kw">rbind</span>(performance, <span class="kw">data.frame</span>(<span class="dt">Format =</span> <span class="st">&#39;Sparse&#39;</span>,
                                                <span class="dt">UserTime =</span> sparse.times[<span class="dv">1</span>],
                                               <span class="dt">SystemTime =</span> sparse.times[<span class="dv">2</span>],
                                               <span class="dt">ElapsedTime =</span> sparse.times[<span class="dv">3</span>],
                                               <span class="dt">Size =</span> sparse.size))
  performance &lt;-<span class="st"> </span><span class="kw">rbind</span>(performance, <span class="kw">data.frame</span>(<span class="dt">Format =</span> <span class="st">&#39;Full&#39;</span>,
                                               <span class="dt">UserTime =</span> full.times[<span class="dv">1</span>],
                                               <span class="dt">SystemTime =</span> full.times[<span class="dv">2</span>],
                                               <span class="dt">ElapsedTime =</span> full.times[<span class="dv">3</span>],
                                               <span class="dt">Size =</span> full.size))
}</code></pre></div>
<p>Things to note:</p>
<ul>
<li>The simulation calls <code>glmnet</code> twice. Once with the non-sparse object <code>x</code>, and once with its sparse version <code>sx</code>.</li>
<li>The degree of sparsity of <code>sx</code> is <span class="math inline">\(85\%\)</span>. We know this because we “injected” zeroes in <span class="math inline">\(0.85\)</span> of the locations of <code>x</code>.</li>
<li>Because <code>y</code> is continuous <code>glmnet</code> will fit a simple OLS model. We will see later how to use it to fit GLMs and use lasso, ridge, and elastic-net regularization.</li>
</ul>
<p>We now inspect the computing time, and the memory footprint, only to discover that sparse representations make a BIG difference.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(<span class="st">&#39;ggplot2&#39;</span>))
<span class="kw">ggplot</span>(performance, <span class="kw">aes</span>(<span class="dt">x =</span> Format, <span class="dt">y =</span> ElapsedTime, <span class="dt">fill =</span> Format)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> <span class="st">&#39;mean_cl_boot&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;bar&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> <span class="st">&#39;mean_cl_boot&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;errorbar&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&#39;Elapsed Time in Seconds&#39;</span>) </code></pre></div>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-276-1.png" width="50%" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(performance, <span class="kw">aes</span>(<span class="dt">x =</span> Format, <span class="dt">y =</span> Size <span class="op">/</span><span class="st"> </span><span class="dv">1000000</span>, <span class="dt">fill =</span> Format)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> <span class="st">&#39;mean_cl_boot&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;bar&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> <span class="st">&#39;mean_cl_boot&#39;</span>, <span class="dt">geom =</span> <span class="st">&#39;errorbar&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&#39;Matrix Size in MB&#39;</span>) </code></pre></div>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-277-1.png" width="50%" /></p>
<p>How do we perform other types of regression with the <strong>glmnet</strong>? We just need to use the <code>family</code> and <code>alpha</code> arguments of <code>glmnet::glmnet</code>. The <code>family</code> argument governs the type of GLM to fit: logistic, Poisson, probit, or other types of GLM. The <code>alpha</code> argument controls the type of regularization. Set to <code>alpha=0</code> for ridge, <code>alpha=1</code> for lasso, and any value in between for elastic-net regularization.</p>
</div>
</div>
<div id="bibliographic-notes-10" class="section level2">
<h2><span class="header-section-number">14.3</span> Bibliographic Notes</h2>
<p>The best place to start reading on sparse representations and algorithms is the <a href="http://svitsrv25.epfl.ch/R-doc/library/Matrix/doc/">vignettes</a> of the <strong>Matrix</strong> package. <span class="citation">Gilbert, Moler, and Schreiber (<a href="#ref-gilbert1992sparse">1992</a>)</span> is also a great read for some general background. For the theory on solving sparse linear systems see <span class="citation">Davis (<a href="#ref-davis2006direct">2006</a>)</span>. For general numerical linear algebra see <span class="citation">Gentle (<a href="#ref-gentle2012numerical">2012</a>)</span>.</p>
</div>
<div id="practice-yourself-12" class="section level2">
<h2><span class="header-section-number">14.4</span> Practice Yourself</h2>

</div>
</div>
<h3> Bibliography</h3>
<div id="refs" class="references">
<div id="ref-shah2004sparse">
<p>Shah, Viral, and John R Gilbert. 2004. “Sparse Matrices in Matlab* P: Design and Implementation.” In <em>International Conference on High-Performance Computing</em>, 144–55. Springer.</p>
</div>
<div id="ref-gilbert1992sparse">
<p>Gilbert, John R, Cleve Moler, and Robert Schreiber. 1992. “Sparse Matrices in Matlab: Design and Implementation.” <em>SIAM Journal on Matrix Analysis and Applications</em> 13 (1). SIAM: 333–56.</p>
</div>
<div id="ref-davis2006direct">
<p>Davis, Timothy A. 2006. <em>Direct Methods for Sparse Linear Systems</em>. SIAM.</p>
</div>
<div id="ref-gentle2012numerical">
<p>Gentle, James E. 2012. <em>Numerical Linear Algebra for Applications in Statistics</em>. Springer Science &amp; Business Media.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hadley.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="memory.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/13-sparsity.Rmd",
"text": "Edit"
},
"download": ["Rcourse.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
