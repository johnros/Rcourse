<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Linear Models | R (BGU course)</title>
  <meta name="description" content="Class notes for the R course at the BGU’s IE&amp;M dept." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Linear Models | R (BGU course)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for the R course at the BGU’s IE&amp;M dept." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Linear Models | R (BGU course)" />
  
  <meta name="twitter:description" content="Class notes for the R course at the BGU’s IE&amp;M dept." />
  

<meta name="author" content="Jonathan D. Rosenblatt" />


<meta name="date" content="2019-10-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="eda.html">
<link rel="next" href="glm.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/sequences-0.1/sequences.css" rel="stylesheet" />
<script src="libs/sunburst-binding-2.1.1/sunburst.js"></script>
<script src="libs/d3-5.7.0/d3.min.js"></script>
<script src="libs/d3-lasso-0.0.5/d3-lasso.min.js"></script>
<link href="libs/ggiraphjs-0.1.0/styles.css" rel="stylesheet" />
<script src="libs/ggiraphjs-0.1.0/ggiraphjs.min.js"></script>
<script src="libs/girafe-binding-0.6.1/girafe.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R Course</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#notation-conventions"><i class="fa fa-check"></i><b>1.1</b> Notation Conventions</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#what-r"><i class="fa fa-check"></i><b>2.1</b> What is R?</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#ecosystem"><i class="fa fa-check"></i><b>2.2</b> The R Ecosystem</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#bibliographic-notes"><i class="fa fa-check"></i><b>2.3</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>3</b> R Basics</a><ul>
<li class="chapter" data-level="3.0.1" data-path="basics.html"><a href="basics.html#other-ides"><i class="fa fa-check"></i><b>3.0.1</b> Other IDEs</a></li>
<li class="chapter" data-level="3.1" data-path="basics.html"><a href="basics.html#file-types"><i class="fa fa-check"></i><b>3.1</b> File types</a></li>
<li class="chapter" data-level="3.2" data-path="basics.html"><a href="basics.html#simple-calculator"><i class="fa fa-check"></i><b>3.2</b> Simple calculator</a></li>
<li class="chapter" data-level="3.3" data-path="basics.html"><a href="basics.html#probability-calculator"><i class="fa fa-check"></i><b>3.3</b> Probability calculator</a></li>
<li class="chapter" data-level="3.4" data-path="basics.html"><a href="basics.html#getting-help"><i class="fa fa-check"></i><b>3.4</b> Getting Help</a></li>
<li class="chapter" data-level="3.5" data-path="basics.html"><a href="basics.html#variable-assignment"><i class="fa fa-check"></i><b>3.5</b> Variable Assignment</a></li>
<li class="chapter" data-level="3.6" data-path="basics.html"><a href="basics.html#missing"><i class="fa fa-check"></i><b>3.6</b> Missing</a></li>
<li class="chapter" data-level="3.7" data-path="basics.html"><a href="basics.html#piping"><i class="fa fa-check"></i><b>3.7</b> Piping</a></li>
<li class="chapter" data-level="3.8" data-path="basics.html"><a href="basics.html#vector-creation-and-manipulation"><i class="fa fa-check"></i><b>3.8</b> Vector Creation and Manipulation</a></li>
<li class="chapter" data-level="3.9" data-path="basics.html"><a href="basics.html#search-paths-and-packages"><i class="fa fa-check"></i><b>3.9</b> Search Paths and Packages</a></li>
<li class="chapter" data-level="3.10" data-path="basics.html"><a href="basics.html#simple-plotting"><i class="fa fa-check"></i><b>3.10</b> Simple Plotting</a></li>
<li class="chapter" data-level="3.11" data-path="basics.html"><a href="basics.html#object-types"><i class="fa fa-check"></i><b>3.11</b> Object Types</a></li>
<li class="chapter" data-level="3.12" data-path="basics.html"><a href="basics.html#data-frames"><i class="fa fa-check"></i><b>3.12</b> Data Frames</a></li>
<li class="chapter" data-level="3.13" data-path="basics.html"><a href="basics.html#exctraction"><i class="fa fa-check"></i><b>3.13</b> Exctraction</a></li>
<li class="chapter" data-level="3.14" data-path="basics.html"><a href="basics.html#augmentations-of-the-data.frame-class"><i class="fa fa-check"></i><b>3.14</b> Augmentations of the data.frame class</a></li>
<li class="chapter" data-level="3.15" data-path="basics.html"><a href="basics.html#data-import-and-export"><i class="fa fa-check"></i><b>3.15</b> Data Import and Export</a><ul>
<li class="chapter" data-level="3.15.1" data-path="basics.html"><a href="basics.html#import-from-web"><i class="fa fa-check"></i><b>3.15.1</b> Import from WEB</a></li>
<li class="chapter" data-level="3.15.2" data-path="basics.html"><a href="basics.html#import-from-clipboard"><i class="fa fa-check"></i><b>3.15.2</b> Import From Clipboard</a></li>
<li class="chapter" data-level="3.15.3" data-path="basics.html"><a href="basics.html#export-as-csv"><i class="fa fa-check"></i><b>3.15.3</b> Export as CSV</a></li>
<li class="chapter" data-level="3.15.4" data-path="basics.html"><a href="basics.html#export-non-csv-files"><i class="fa fa-check"></i><b>3.15.4</b> Export non-CSV files</a></li>
<li class="chapter" data-level="3.15.5" data-path="basics.html"><a href="basics.html#reading-from-text-files"><i class="fa fa-check"></i><b>3.15.5</b> Reading From Text Files</a></li>
<li class="chapter" data-level="3.15.6" data-path="basics.html"><a href="basics.html#writing-data-to-text-files"><i class="fa fa-check"></i><b>3.15.6</b> Writing Data to Text Files</a></li>
<li class="chapter" data-level="3.15.7" data-path="basics.html"><a href="basics.html#xlsx-files"><i class="fa fa-check"></i><b>3.15.7</b> .XLS(X) files</a></li>
<li class="chapter" data-level="3.15.8" data-path="basics.html"><a href="basics.html#massive-files"><i class="fa fa-check"></i><b>3.15.8</b> Massive files</a></li>
<li class="chapter" data-level="3.15.9" data-path="basics.html"><a href="basics.html#databases"><i class="fa fa-check"></i><b>3.15.9</b> Databases</a></li>
</ul></li>
<li class="chapter" data-level="3.16" data-path="basics.html"><a href="basics.html#functions"><i class="fa fa-check"></i><b>3.16</b> Functions</a></li>
<li class="chapter" data-level="3.17" data-path="basics.html"><a href="basics.html#looping"><i class="fa fa-check"></i><b>3.17</b> Looping</a></li>
<li class="chapter" data-level="3.18" data-path="basics.html"><a href="basics.html#apply"><i class="fa fa-check"></i><b>3.18</b> Apply</a></li>
<li class="chapter" data-level="3.19" data-path="basics.html"><a href="basics.html#recursion"><i class="fa fa-check"></i><b>3.19</b> Recursion</a></li>
<li class="chapter" data-level="3.20" data-path="basics.html"><a href="basics.html#strings"><i class="fa fa-check"></i><b>3.20</b> Strings</a></li>
<li class="chapter" data-level="3.21" data-path="basics.html"><a href="basics.html#dates-and-times"><i class="fa fa-check"></i><b>3.21</b> Dates and Times</a><ul>
<li class="chapter" data-level="3.21.1" data-path="basics.html"><a href="basics.html#dates"><i class="fa fa-check"></i><b>3.21.1</b> Dates</a></li>
<li class="chapter" data-level="3.21.2" data-path="basics.html"><a href="basics.html#times"><i class="fa fa-check"></i><b>3.21.2</b> Times</a></li>
<li class="chapter" data-level="3.21.3" data-path="basics.html"><a href="basics.html#lubridate-package"><i class="fa fa-check"></i><b>3.21.3</b> lubridate Package</a></li>
</ul></li>
<li class="chapter" data-level="3.22" data-path="basics.html"><a href="basics.html#complex-objects"><i class="fa fa-check"></i><b>3.22</b> Complex Objects</a></li>
<li class="chapter" data-level="3.23" data-path="basics.html"><a href="basics.html#vectors-and-matrix-products"><i class="fa fa-check"></i><b>3.23</b> Vectors and Matrix Products</a></li>
<li class="chapter" data-level="3.24" data-path="basics.html"><a href="basics.html#rstudio-projects"><i class="fa fa-check"></i><b>3.24</b> RStudio Projects</a></li>
<li class="chapter" data-level="3.25" data-path="basics.html"><a href="basics.html#bibliographic-notes-1"><i class="fa fa-check"></i><b>3.25</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="3.26" data-path="basics.html"><a href="basics.html#practice-yourself"><i class="fa fa-check"></i><b>3.26</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="datatable.html"><a href="datatable.html"><i class="fa fa-check"></i><b>4</b> data.table</a><ul>
<li class="chapter" data-level="4.1" data-path="datatable.html"><a href="datatable.html#make-your-own-variables"><i class="fa fa-check"></i><b>4.1</b> Make your own variables</a></li>
<li class="chapter" data-level="4.2" data-path="datatable.html"><a href="datatable.html#join"><i class="fa fa-check"></i><b>4.2</b> Join</a></li>
<li class="chapter" data-level="4.3" data-path="datatable.html"><a href="datatable.html#reshaping-data"><i class="fa fa-check"></i><b>4.3</b> Reshaping data</a><ul>
<li class="chapter" data-level="4.3.1" data-path="datatable.html"><a href="datatable.html#wide-to-long"><i class="fa fa-check"></i><b>4.3.1</b> Wide to long</a></li>
<li class="chapter" data-level="4.3.2" data-path="datatable.html"><a href="datatable.html#long-to-wide"><i class="fa fa-check"></i><b>4.3.2</b> Long to wide</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="datatable.html"><a href="datatable.html#bibliographic-notes-2"><i class="fa fa-check"></i><b>4.4</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="4.5" data-path="datatable.html"><a href="datatable.html#practice-yourself-1"><i class="fa fa-check"></i><b>4.5</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>5</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="5.1" data-path="eda.html"><a href="eda.html#summary-statistics"><i class="fa fa-check"></i><b>5.1</b> Summary Statistics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="eda.html"><a href="eda.html#categorical-data"><i class="fa fa-check"></i><b>5.1.1</b> Categorical Data</a></li>
<li class="chapter" data-level="5.1.2" data-path="eda.html"><a href="eda.html#continous-data"><i class="fa fa-check"></i><b>5.1.2</b> Continous Data</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="eda.html"><a href="eda.html#visualization"><i class="fa fa-check"></i><b>5.2</b> Visualization</a><ul>
<li class="chapter" data-level="5.2.1" data-path="eda.html"><a href="eda.html#categorical-data-1"><i class="fa fa-check"></i><b>5.2.1</b> Categorical Data</a></li>
<li class="chapter" data-level="5.2.2" data-path="eda.html"><a href="eda.html#continuous-data"><i class="fa fa-check"></i><b>5.2.2</b> Continuous Data</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="eda.html"><a href="eda.html#mixed-type-data"><i class="fa fa-check"></i><b>5.3</b> Mixed Type Data</a><ul>
<li class="chapter" data-level="5.3.1" data-path="eda.html"><a href="eda.html#alluvial"><i class="fa fa-check"></i><b>5.3.1</b> Alluvial Diagram</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="eda.html"><a href="eda.html#bibliographic-notes-3"><i class="fa fa-check"></i><b>5.4</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="5.5" data-path="eda.html"><a href="eda.html#practice-yourself-2"><i class="fa fa-check"></i><b>5.5</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>6</b> Linear Models</a><ul>
<li class="chapter" data-level="6.1" data-path="lm.html"><a href="lm.html#problem-setup"><i class="fa fa-check"></i><b>6.1</b> Problem Setup</a></li>
<li class="chapter" data-level="6.2" data-path="lm.html"><a href="lm.html#ols-estimation-in-r"><i class="fa fa-check"></i><b>6.2</b> OLS Estimation in R</a></li>
<li class="chapter" data-level="6.3" data-path="lm.html"><a href="lm.html#inference"><i class="fa fa-check"></i><b>6.3</b> Inference</a><ul>
<li class="chapter" data-level="6.3.1" data-path="lm.html"><a href="lm.html#testing-a-hypothesis-on-a-single-coefficient"><i class="fa fa-check"></i><b>6.3.1</b> Testing a Hypothesis on a Single Coefficient</a></li>
<li class="chapter" data-level="6.3.2" data-path="lm.html"><a href="lm.html#constructing-a-confidence-interval-on-a-single-coefficient"><i class="fa fa-check"></i><b>6.3.2</b> Constructing a Confidence Interval on a Single Coefficient</a></li>
<li class="chapter" data-level="6.3.3" data-path="lm.html"><a href="lm.html#multiple-regression"><i class="fa fa-check"></i><b>6.3.3</b> Multiple Regression</a></li>
<li class="chapter" data-level="6.3.4" data-path="lm.html"><a href="lm.html#anova"><i class="fa fa-check"></i><b>6.3.4</b> ANOVA (*)</a></li>
<li class="chapter" data-level="6.3.5" data-path="lm.html"><a href="lm.html#testing-a-hypothesis-on-a-single-contrast"><i class="fa fa-check"></i><b>6.3.5</b> Testing a Hypothesis on a Single Contrast (*)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="lm.html"><a href="lm.html#extra-diagnostics"><i class="fa fa-check"></i><b>6.4</b> Extra Diagnostics</a><ul>
<li class="chapter" data-level="6.4.1" data-path="lm.html"><a href="lm.html#diagnosing-heteroskedasticity"><i class="fa fa-check"></i><b>6.4.1</b> Diagnosing Heteroskedasticity</a></li>
<li class="chapter" data-level="6.4.2" data-path="lm.html"><a href="lm.html#diagnosing-multicolinearity"><i class="fa fa-check"></i><b>6.4.2</b> Diagnosing Multicolinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="lm.html"><a href="lm.html#bibliographic-notes-4"><i class="fa fa-check"></i><b>6.5</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="6.6" data-path="lm.html"><a href="lm.html#practice-yourself-3"><i class="fa fa-check"></i><b>6.6</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="7.1" data-path="glm.html"><a href="glm.html#problem-setup-1"><i class="fa fa-check"></i><b>7.1</b> Problem Setup</a></li>
<li class="chapter" data-level="7.2" data-path="glm.html"><a href="glm.html#logistic-regression"><i class="fa fa-check"></i><b>7.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="7.2.1" data-path="glm.html"><a href="glm.html#logistic-regression-with-r"><i class="fa fa-check"></i><b>7.2.1</b> Logistic Regression with R</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="glm.html"><a href="glm.html#poisson-regression"><i class="fa fa-check"></i><b>7.3</b> Poisson Regression</a></li>
<li class="chapter" data-level="7.4" data-path="glm.html"><a href="glm.html#extensions"><i class="fa fa-check"></i><b>7.4</b> Extensions</a></li>
<li class="chapter" data-level="7.5" data-path="glm.html"><a href="glm.html#bibliographic-notes-5"><i class="fa fa-check"></i><b>7.5</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="7.6" data-path="glm.html"><a href="glm.html#practice-glm"><i class="fa fa-check"></i><b>7.6</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="lme.html"><a href="lme.html"><i class="fa fa-check"></i><b>8</b> Linear Mixed Models</a><ul>
<li class="chapter" data-level="8.1" data-path="lme.html"><a href="lme.html#problem-setup-2"><i class="fa fa-check"></i><b>8.1</b> Problem Setup</a><ul>
<li class="chapter" data-level="8.1.1" data-path="lme.html"><a href="lme.html#non-linear-mixed-models"><i class="fa fa-check"></i><b>8.1.1</b> Non-Linear Mixed Models</a></li>
<li class="chapter" data-level="8.1.2" data-path="lme.html"><a href="lme.html#generalized-linear-mixed-models-glmm"><i class="fa fa-check"></i><b>8.1.2</b> Generalized Linear Mixed Models (GLMM)</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="lme.html"><a href="lme.html#mixed-models-with-r"><i class="fa fa-check"></i><b>8.2</b> Mixed Models with R</a><ul>
<li class="chapter" data-level="8.2.1" data-path="lme.html"><a href="lme.html#a-single-random-effect"><i class="fa fa-check"></i><b>8.2.1</b> A Single Random Effect</a></li>
<li class="chapter" data-level="8.2.2" data-path="lme.html"><a href="lme.html#multiple-random-effects"><i class="fa fa-check"></i><b>8.2.2</b> Multiple Random Effects</a></li>
<li class="chapter" data-level="8.2.3" data-path="lme.html"><a href="lme.html#a-full-mixed-model"><i class="fa fa-check"></i><b>8.2.3</b> A Full Mixed-Model</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="lme.html"><a href="lme.html#serial"><i class="fa fa-check"></i><b>8.3</b> Serial Correlations</a></li>
<li class="chapter" data-level="8.4" data-path="lme.html"><a href="lme.html#extensions-1"><i class="fa fa-check"></i><b>8.4</b> Extensions</a><ul>
<li class="chapter" data-level="8.4.1" data-path="lme.html"><a href="lme.html#cr-se"><i class="fa fa-check"></i><b>8.4.1</b> Cluster Robust Standard Errors</a></li>
<li class="chapter" data-level="8.4.2" data-path="lme.html"><a href="lme.html#linear-models-for-panel-data"><i class="fa fa-check"></i><b>8.4.2</b> Linear Models for Panel Data</a></li>
<li class="chapter" data-level="8.4.3" data-path="lme.html"><a href="lme.html#testing-hypotheses-on-correlations"><i class="fa fa-check"></i><b>8.4.3</b> Testing Hypotheses on Correlations</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="lme.html"><a href="lme.html#relation-to-other-estimators"><i class="fa fa-check"></i><b>8.5</b> Relation to Other Estimators</a><ul>
<li class="chapter" data-level="8.5.1" data-path="lme.html"><a href="lme.html#fixed-effects-in-the-econometric-literature"><i class="fa fa-check"></i><b>8.5.1</b> Fixed Effects in the Econometric Literature</a></li>
<li class="chapter" data-level="8.5.2" data-path="lme.html"><a href="lme.html#relation-to-generalized-least-squares-gls"><i class="fa fa-check"></i><b>8.5.2</b> Relation to Generalized Least Squares (GLS)</a></li>
<li class="chapter" data-level="8.5.3" data-path="lme.html"><a href="lme.html#relation-to-conditional-gaussian-fields"><i class="fa fa-check"></i><b>8.5.3</b> Relation to Conditional Gaussian Fields</a></li>
<li class="chapter" data-level="8.5.4" data-path="lme.html"><a href="lme.html#relation-to-empirical-risk-minimization-erm"><i class="fa fa-check"></i><b>8.5.4</b> Relation to Empirical Risk Minimization (ERM)</a></li>
<li class="chapter" data-level="8.5.5" data-path="lme.html"><a href="lme.html#relation-to-m-estimation"><i class="fa fa-check"></i><b>8.5.5</b> Relation to M-Estimation</a></li>
<li class="chapter" data-level="8.5.6" data-path="lme.html"><a href="lme.html#relation-to-generalize-estimating-equations-gee"><i class="fa fa-check"></i><b>8.5.6</b> Relation to Generalize Estimating Equations (GEE)</a></li>
<li class="chapter" data-level="8.5.7" data-path="lme.html"><a href="lme.html#manova"><i class="fa fa-check"></i><b>8.5.7</b> Relation to MANOVA</a></li>
<li class="chapter" data-level="8.5.8" data-path="lme.html"><a href="lme.html#relation-to-seemingly-unrelated-equations-sur"><i class="fa fa-check"></i><b>8.5.8</b> Relation to Seemingly Unrelated Equations (SUR)</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="lme.html"><a href="lme.html#bibliographic-notes-6"><i class="fa fa-check"></i><b>8.6</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="8.7" data-path="lme.html"><a href="lme.html#practice-yourself-4"><i class="fa fa-check"></i><b>8.7</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="multivariate.html"><a href="multivariate.html"><i class="fa fa-check"></i><b>9</b> Multivariate Data Analysis</a><ul>
<li class="chapter" data-level="9.1" data-path="multivariate.html"><a href="multivariate.html#signal-detection"><i class="fa fa-check"></i><b>9.1</b> Signal Detection</a><ul>
<li class="chapter" data-level="9.1.1" data-path="multivariate.html"><a href="multivariate.html#hotellings-t2-test"><i class="fa fa-check"></i><b>9.1.1</b> Hotelling’s T2 Test</a></li>
<li class="chapter" data-level="9.1.2" data-path="multivariate.html"><a href="multivariate.html#various-types-of-signal-to-detect"><i class="fa fa-check"></i><b>9.1.2</b> Various Types of Signal to Detect</a></li>
<li class="chapter" data-level="9.1.3" data-path="multivariate.html"><a href="multivariate.html#simes-test"><i class="fa fa-check"></i><b>9.1.3</b> Simes’ Test</a></li>
<li class="chapter" data-level="9.1.4" data-path="multivariate.html"><a href="multivariate.html#signal-detection-with-r"><i class="fa fa-check"></i><b>9.1.4</b> Signal Detection with R</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="multivariate.html"><a href="multivariate.html#signal-counting"><i class="fa fa-check"></i><b>9.2</b> Signal Counting</a></li>
<li class="chapter" data-level="9.3" data-path="multivariate.html"><a href="multivariate.html#identification"><i class="fa fa-check"></i><b>9.3</b> Signal Identification</a><ul>
<li class="chapter" data-level="9.3.1" data-path="multivariate.html"><a href="multivariate.html#signal-identification-in-r"><i class="fa fa-check"></i><b>9.3.1</b> Signal Identification in R</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="multivariate.html"><a href="multivariate.html#signal-estimation"><i class="fa fa-check"></i><b>9.4</b> Signal Estimation (*)</a></li>
<li class="chapter" data-level="9.5" data-path="multivariate.html"><a href="multivariate.html#bibliographic-notes-7"><i class="fa fa-check"></i><b>9.5</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="9.6" data-path="multivariate.html"><a href="multivariate.html#practice-yourself-5"><i class="fa fa-check"></i><b>9.6</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="supervised.html"><a href="supervised.html"><i class="fa fa-check"></i><b>10</b> Supervised Learning</a><ul>
<li class="chapter" data-level="10.1" data-path="supervised.html"><a href="supervised.html#problem-setup-3"><i class="fa fa-check"></i><b>10.1</b> Problem Setup</a><ul>
<li class="chapter" data-level="10.1.1" data-path="supervised.html"><a href="supervised.html#common-hypothesis-classes"><i class="fa fa-check"></i><b>10.1.1</b> Common Hypothesis Classes</a></li>
<li class="chapter" data-level="10.1.2" data-path="supervised.html"><a href="supervised.html#common-complexity-penalties"><i class="fa fa-check"></i><b>10.1.2</b> Common Complexity Penalties</a></li>
<li class="chapter" data-level="10.1.3" data-path="supervised.html"><a href="supervised.html#unbiased-risk-estimation"><i class="fa fa-check"></i><b>10.1.3</b> Unbiased Risk Estimation</a></li>
<li class="chapter" data-level="10.1.4" data-path="supervised.html"><a href="supervised.html#collecting-the-pieces"><i class="fa fa-check"></i><b>10.1.4</b> Collecting the Pieces</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="supervised.html"><a href="supervised.html#supervised-learning-in-r"><i class="fa fa-check"></i><b>10.2</b> Supervised Learning in R</a><ul>
<li class="chapter" data-level="10.2.1" data-path="supervised.html"><a href="supervised.html#least-squares"><i class="fa fa-check"></i><b>10.2.1</b> Linear Models with Least Squares Loss</a></li>
<li class="chapter" data-level="10.2.2" data-path="supervised.html"><a href="supervised.html#svm"><i class="fa fa-check"></i><b>10.2.2</b> SVM</a></li>
<li class="chapter" data-level="10.2.3" data-path="supervised.html"><a href="supervised.html#neural-nets"><i class="fa fa-check"></i><b>10.2.3</b> Neural Nets</a></li>
<li class="chapter" data-level="10.2.4" data-path="supervised.html"><a href="supervised.html#trees"><i class="fa fa-check"></i><b>10.2.4</b> Classification and Regression Trees (CART)</a></li>
<li class="chapter" data-level="10.2.5" data-path="supervised.html"><a href="supervised.html#k-nearest-neighbour-knn"><i class="fa fa-check"></i><b>10.2.5</b> K-nearest neighbour (KNN)</a></li>
<li class="chapter" data-level="10.2.6" data-path="supervised.html"><a href="supervised.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>10.2.6</b> Linear Discriminant Analysis (LDA)</a></li>
<li class="chapter" data-level="10.2.7" data-path="supervised.html"><a href="supervised.html#naive-bayes"><i class="fa fa-check"></i><b>10.2.7</b> Naive Bayes</a></li>
<li class="chapter" data-level="10.2.8" data-path="supervised.html"><a href="supervised.html#random-forrest"><i class="fa fa-check"></i><b>10.2.8</b> Random Forrest</a></li>
<li class="chapter" data-level="10.2.9" data-path="supervised.html"><a href="supervised.html#boosting"><i class="fa fa-check"></i><b>10.2.9</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="supervised.html"><a href="supervised.html#bibliographic-notes-8"><i class="fa fa-check"></i><b>10.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="10.4" data-path="supervised.html"><a href="supervised.html#practice-yourself-6"><i class="fa fa-check"></i><b>10.4</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="unsupervised.html"><a href="unsupervised.html"><i class="fa fa-check"></i><b>11</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="11.1" data-path="unsupervised.html"><a href="unsupervised.html#dim-reduce"><i class="fa fa-check"></i><b>11.1</b> Dimensionality Reduction</a><ul>
<li class="chapter" data-level="11.1.1" data-path="unsupervised.html"><a href="unsupervised.html#pca"><i class="fa fa-check"></i><b>11.1.1</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="11.1.2" data-path="unsupervised.html"><a href="unsupervised.html#dimensionality-reduction-preliminaries"><i class="fa fa-check"></i><b>11.1.2</b> Dimensionality Reduction Preliminaries</a></li>
<li class="chapter" data-level="11.1.3" data-path="unsupervised.html"><a href="unsupervised.html#latent-variable-generative-approaches"><i class="fa fa-check"></i><b>11.1.3</b> Latent Variable Generative Approaches</a></li>
<li class="chapter" data-level="11.1.4" data-path="unsupervised.html"><a href="unsupervised.html#purely-algorithmic-approaches"><i class="fa fa-check"></i><b>11.1.4</b> Purely Algorithmic Approaches</a></li>
<li class="chapter" data-level="11.1.5" data-path="unsupervised.html"><a href="unsupervised.html#dimensionality-reduction-in-r"><i class="fa fa-check"></i><b>11.1.5</b> Dimensionality Reduction in R</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="unsupervised.html"><a href="unsupervised.html#cluster"><i class="fa fa-check"></i><b>11.2</b> Clustering</a><ul>
<li class="chapter" data-level="11.2.1" data-path="unsupervised.html"><a href="unsupervised.html#latent-variable-generative-approaches-1"><i class="fa fa-check"></i><b>11.2.1</b> Latent Variable Generative Approaches</a></li>
<li class="chapter" data-level="11.2.2" data-path="unsupervised.html"><a href="unsupervised.html#purely-algorithmic-approaches-1"><i class="fa fa-check"></i><b>11.2.2</b> Purely Algorithmic Approaches</a></li>
<li class="chapter" data-level="11.2.3" data-path="unsupervised.html"><a href="unsupervised.html#clustering-in-r"><i class="fa fa-check"></i><b>11.2.3</b> Clustering in R</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="unsupervised.html"><a href="unsupervised.html#bibliographic-notes-9"><i class="fa fa-check"></i><b>11.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="11.4" data-path="unsupervised.html"><a href="unsupervised.html#practice-yourself-7"><i class="fa fa-check"></i><b>11.4</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="plotting.html"><a href="plotting.html"><i class="fa fa-check"></i><b>12</b> Plotting</a><ul>
<li class="chapter" data-level="12.1" data-path="plotting.html"><a href="plotting.html#the-graphics-system"><i class="fa fa-check"></i><b>12.1</b> The graphics System</a><ul>
<li class="chapter" data-level="12.1.1" data-path="plotting.html"><a href="plotting.html#using-existing-plotting-functions"><i class="fa fa-check"></i><b>12.1.1</b> Using Existing Plotting Functions</a></li>
<li class="chapter" data-level="12.1.2" data-path="plotting.html"><a href="plotting.html#exporting-a-plot"><i class="fa fa-check"></i><b>12.1.2</b> Exporting a Plot</a></li>
<li class="chapter" data-level="12.1.3" data-path="plotting.html"><a href="plotting.html#fancy"><i class="fa fa-check"></i><b>12.1.3</b> Fancy graphics Examples</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="plotting.html"><a href="plotting.html#the-ggplot2-system"><i class="fa fa-check"></i><b>12.2</b> The ggplot2 System</a><ul>
<li class="chapter" data-level="12.2.1" data-path="plotting.html"><a href="plotting.html#extensions-of-the-ggplot2-system"><i class="fa fa-check"></i><b>12.2.1</b> Extensions of the ggplot2 System</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="plotting.html"><a href="plotting.html#interactive-graphics"><i class="fa fa-check"></i><b>12.3</b> Interactive Graphics</a><ul>
<li class="chapter" data-level="12.3.1" data-path="plotting.html"><a href="plotting.html#plotly"><i class="fa fa-check"></i><b>12.3.1</b> Plotly</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="plotting.html"><a href="plotting.html#other-r-interfaces-to-javascript-plotting"><i class="fa fa-check"></i><b>12.4</b> Other R Interfaces to JavaScript Plotting</a></li>
<li class="chapter" data-level="12.5" data-path="plotting.html"><a href="plotting.html#bibliographic-notes-10"><i class="fa fa-check"></i><b>12.5</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="12.6" data-path="plotting.html"><a href="plotting.html#practice-yourself-8"><i class="fa fa-check"></i><b>12.6</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="report.html"><a href="report.html"><i class="fa fa-check"></i><b>13</b> Reports</a><ul>
<li class="chapter" data-level="13.1" data-path="report.html"><a href="report.html#knitr"><i class="fa fa-check"></i><b>13.1</b> knitr</a><ul>
<li class="chapter" data-level="13.1.1" data-path="report.html"><a href="report.html#installation"><i class="fa fa-check"></i><b>13.1.1</b> Installation</a></li>
<li class="chapter" data-level="13.1.2" data-path="report.html"><a href="report.html#pandoc-markdown"><i class="fa fa-check"></i><b>13.1.2</b> Pandoc Markdown</a></li>
<li class="chapter" data-level="13.1.3" data-path="report.html"><a href="report.html#rmarkdown"><i class="fa fa-check"></i><b>13.1.3</b> Rmarkdown</a></li>
<li class="chapter" data-level="13.1.4" data-path="report.html"><a href="report.html#bibtex"><i class="fa fa-check"></i><b>13.1.4</b> BibTex</a></li>
<li class="chapter" data-level="13.1.5" data-path="report.html"><a href="report.html#compiling"><i class="fa fa-check"></i><b>13.1.5</b> Compiling</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="report.html"><a href="report.html#bookdown"><i class="fa fa-check"></i><b>13.2</b> bookdown</a></li>
<li class="chapter" data-level="13.3" data-path="report.html"><a href="report.html#shiny"><i class="fa fa-check"></i><b>13.3</b> Shiny</a><ul>
<li class="chapter" data-level="13.3.1" data-path="report.html"><a href="report.html#installation-1"><i class="fa fa-check"></i><b>13.3.1</b> Installation</a></li>
<li class="chapter" data-level="13.3.2" data-path="report.html"><a href="report.html#the-basics-of-shiny"><i class="fa fa-check"></i><b>13.3.2</b> The Basics of Shiny</a></li>
<li class="chapter" data-level="13.3.3" data-path="report.html"><a href="report.html#beyond-the-basics"><i class="fa fa-check"></i><b>13.3.3</b> Beyond the Basics</a></li>
<li class="chapter" data-level="13.3.4" data-path="report.html"><a href="report.html#shinydashboard"><i class="fa fa-check"></i><b>13.3.4</b> shinydashboard</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="report.html"><a href="report.html#flexdashboard"><i class="fa fa-check"></i><b>13.4</b> flexdashboard</a></li>
<li class="chapter" data-level="13.5" data-path="report.html"><a href="report.html#bibliographic-notes-11"><i class="fa fa-check"></i><b>13.5</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="13.6" data-path="report.html"><a href="report.html#practice-yourself-9"><i class="fa fa-check"></i><b>13.6</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="sparse.html"><a href="sparse.html"><i class="fa fa-check"></i><b>14</b> Sparse Representations</a><ul>
<li class="chapter" data-level="14.1" data-path="sparse.html"><a href="sparse.html#sparse-matrix-representations"><i class="fa fa-check"></i><b>14.1</b> Sparse Matrix Representations</a><ul>
<li class="chapter" data-level="14.1.1" data-path="sparse.html"><a href="sparse.html#coo"><i class="fa fa-check"></i><b>14.1.1</b> Coordinate List Representation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sparse.html"><a href="sparse.html#compressed-row-oriented-representation"><i class="fa fa-check"></i><b>14.1.2</b> Compressed Row Oriented Representation</a></li>
<li class="chapter" data-level="14.1.3" data-path="sparse.html"><a href="sparse.html#compressed-column-oriented-representation"><i class="fa fa-check"></i><b>14.1.3</b> Compressed Column Oriented Representation</a></li>
<li class="chapter" data-level="14.1.4" data-path="sparse.html"><a href="sparse.html#sparse-algorithms"><i class="fa fa-check"></i><b>14.1.4</b> Sparse Algorithms</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sparse.html"><a href="sparse.html#sparse-matrices-and-sparse-models-in-r"><i class="fa fa-check"></i><b>14.2</b> Sparse Matrices and Sparse Models in R</a><ul>
<li class="chapter" data-level="14.2.1" data-path="sparse.html"><a href="sparse.html#the-matrix-package"><i class="fa fa-check"></i><b>14.2.1</b> The Matrix Package</a></li>
<li class="chapter" data-level="14.2.2" data-path="sparse.html"><a href="sparse.html#the-glmnet-package"><i class="fa fa-check"></i><b>14.2.2</b> The glmnet Package</a></li>
<li class="chapter" data-level="14.2.3" data-path="sparse.html"><a href="sparse.html#the-matrixmodels-package"><i class="fa fa-check"></i><b>14.2.3</b> The MatrixModels Package</a></li>
<li class="chapter" data-level="14.2.4" data-path="sparse.html"><a href="sparse.html#the-sparsem-package"><i class="fa fa-check"></i><b>14.2.4</b> The SparseM Package</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="sparse.html"><a href="sparse.html#beyond-sparsity"><i class="fa fa-check"></i><b>14.3</b> Beyond Sparsity</a></li>
<li class="chapter" data-level="14.4" data-path="sparse.html"><a href="sparse.html#apache-arrow"><i class="fa fa-check"></i><b>14.4</b> Apache Arrow</a></li>
<li class="chapter" data-level="14.5" data-path="sparse.html"><a href="sparse.html#bibliographic-notes-12"><i class="fa fa-check"></i><b>14.5</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="14.6" data-path="sparse.html"><a href="sparse.html#practice-yourself-10"><i class="fa fa-check"></i><b>14.6</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="memory.html"><a href="memory.html"><i class="fa fa-check"></i><b>15</b> Memory Efficiency</a><ul>
<li class="chapter" data-level="15.1" data-path="memory.html"><a href="memory.html#efficient-computing-from-ram"><i class="fa fa-check"></i><b>15.1</b> Efficient Computing from RAM</a><ul>
<li class="chapter" data-level="15.1.1" data-path="memory.html"><a href="memory.html#summary-statistics-from-ram"><i class="fa fa-check"></i><b>15.1.1</b> Summary Statistics from RAM</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="memory.html"><a href="memory.html#computing-from-a-database"><i class="fa fa-check"></i><b>15.2</b> Computing from a Database</a></li>
<li class="chapter" data-level="15.3" data-path="memory.html"><a href="memory.html#file-structure"><i class="fa fa-check"></i><b>15.3</b> Computing From Efficient File Structrures</a><ul>
<li class="chapter" data-level="15.3.1" data-path="memory.html"><a href="memory.html#bigmemory"><i class="fa fa-check"></i><b>15.3.1</b> bigmemory</a></li>
<li class="chapter" data-level="15.3.2" data-path="memory.html"><a href="memory.html#bigstep"><i class="fa fa-check"></i><b>15.3.2</b> bigstep</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="memory.html"><a href="memory.html#ff"><i class="fa fa-check"></i><b>15.4</b> ff</a></li>
<li class="chapter" data-level="15.5" data-path="memory.html"><a href="memory.html#disk.frame"><i class="fa fa-check"></i><b>15.5</b> disk.frame</a></li>
<li class="chapter" data-level="15.6" data-path="memory.html"><a href="memory.html#matter"><i class="fa fa-check"></i><b>15.6</b> matter</a></li>
<li class="chapter" data-level="15.7" data-path="memory.html"><a href="memory.html#iotools"><i class="fa fa-check"></i><b>15.7</b> iotools</a></li>
<li class="chapter" data-level="15.8" data-path="memory.html"><a href="memory.html#hdf5"><i class="fa fa-check"></i><b>15.8</b> HDF5</a></li>
<li class="chapter" data-level="15.9" data-path="memory.html"><a href="memory.html#delayedarray"><i class="fa fa-check"></i><b>15.9</b> DelayedArray</a></li>
<li class="chapter" data-level="15.10" data-path="memory.html"><a href="memory.html#computing-from-a-distributed-file-system"><i class="fa fa-check"></i><b>15.10</b> Computing from a Distributed File System</a></li>
<li class="chapter" data-level="15.11" data-path="memory.html"><a href="memory.html#bibliographic-notes-13"><i class="fa fa-check"></i><b>15.11</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="15.12" data-path="memory.html"><a href="memory.html#practice-yourself-11"><i class="fa fa-check"></i><b>15.12</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="parallel.html"><a href="parallel.html"><i class="fa fa-check"></i><b>16</b> Parallel Computing</a><ul>
<li class="chapter" data-level="16.1" data-path="parallel.html"><a href="parallel.html#when-and-how-to-parallelise"><i class="fa fa-check"></i><b>16.1</b> When and How to Parallelise?</a></li>
<li class="chapter" data-level="16.2" data-path="parallel.html"><a href="parallel.html#terminology"><i class="fa fa-check"></i><b>16.2</b> Terminology</a><ul>
<li class="chapter" data-level="16.2.1" data-path="parallel.html"><a href="parallel.html#hardware"><i class="fa fa-check"></i><b>16.2.1</b> Hardware:</a></li>
<li class="chapter" data-level="16.2.2" data-path="parallel.html"><a href="parallel.html#software"><i class="fa fa-check"></i><b>16.2.2</b> Software:</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="parallel.html"><a href="parallel.html#parallel-r"><i class="fa fa-check"></i><b>16.3</b> Parallel R</a><ul>
<li class="chapter" data-level="16.3.1" data-path="parallel.html"><a href="parallel.html#starting-a-new-r-processes"><i class="fa fa-check"></i><b>16.3.1</b> Starting a New R Processes</a></li>
<li class="chapter" data-level="16.3.2" data-path="parallel.html"><a href="parallel.html#inter-process-communication"><i class="fa fa-check"></i><b>16.3.2</b> Inter-process Communication</a></li>
<li class="chapter" data-level="16.3.3" data-path="parallel.html"><a href="parallel.html#the-parallel-package"><i class="fa fa-check"></i><b>16.3.3</b> The parallel Package</a></li>
<li class="chapter" data-level="16.3.4" data-path="parallel.html"><a href="parallel.html#the-foreach-package"><i class="fa fa-check"></i><b>16.3.4</b> The foreach Package</a></li>
<li class="chapter" data-level="16.3.5" data-path="parallel.html"><a href="parallel.html#rdsm"><i class="fa fa-check"></i><b>16.3.5</b> Rdsm</a></li>
<li class="chapter" data-level="16.3.6" data-path="parallel.html"><a href="parallel.html#pbdr"><i class="fa fa-check"></i><b>16.3.6</b> pbdR</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="parallel.html"><a href="parallel.html#parallel-extensions"><i class="fa fa-check"></i><b>16.4</b> Parallel Extensions</a><ul>
<li class="chapter" data-level="16.4.1" data-path="parallel.html"><a href="parallel.html#parallel-linear-algebra"><i class="fa fa-check"></i><b>16.4.1</b> Parallel Linear Algebra</a></li>
<li class="chapter" data-level="16.4.2" data-path="parallel.html"><a href="parallel.html#parallel-data-munging-with-data.table"><i class="fa fa-check"></i><b>16.4.2</b> Parallel Data Munging with data.table</a></li>
<li class="chapter" data-level="16.4.3" data-path="parallel.html"><a href="parallel.html#spark"><i class="fa fa-check"></i><b>16.4.3</b> Spark</a></li>
<li class="chapter" data-level="16.4.4" data-path="parallel.html"><a href="parallel.html#h2o"><i class="fa fa-check"></i><b>16.4.4</b> H2O</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="parallel.html"><a href="parallel.html#nested-parallel"><i class="fa fa-check"></i><b>16.5</b> Caution: Nested Parallelism</a></li>
<li class="chapter" data-level="16.6" data-path="parallel.html"><a href="parallel.html#bibliographic-notes-14"><i class="fa fa-check"></i><b>16.6</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="16.7" data-path="parallel.html"><a href="parallel.html#practice-yourself-12"><i class="fa fa-check"></i><b>16.7</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="algebra.html"><a href="algebra.html"><i class="fa fa-check"></i><b>17</b> Numerical Linear Algebra</a><ul>
<li class="chapter" data-level="17.1" data-path="algebra.html"><a href="algebra.html#lu-factorization"><i class="fa fa-check"></i><b>17.1</b> LU Factorization</a></li>
<li class="chapter" data-level="17.2" data-path="algebra.html"><a href="algebra.html#cholesky-factorization"><i class="fa fa-check"></i><b>17.2</b> Cholesky Factorization</a></li>
<li class="chapter" data-level="17.3" data-path="algebra.html"><a href="algebra.html#qr-factorization"><i class="fa fa-check"></i><b>17.3</b> QR Factorization</a></li>
<li class="chapter" data-level="17.4" data-path="algebra.html"><a href="algebra.html#singular-value-factorization"><i class="fa fa-check"></i><b>17.4</b> Singular Value Factorization</a></li>
<li class="chapter" data-level="17.5" data-path="algebra.html"><a href="algebra.html#iterative-methods"><i class="fa fa-check"></i><b>17.5</b> Iterative Methods</a></li>
<li class="chapter" data-level="17.6" data-path="algebra.html"><a href="algebra.html#solving-ols"><i class="fa fa-check"></i><b>17.6</b> Solving the OLS Problem</a></li>
<li class="chapter" data-level="17.7" data-path="algebra.html"><a href="algebra.html#numerical-libraries-for-linear-algebra"><i class="fa fa-check"></i><b>17.7</b> Numerical Libraries for Linear Algebra</a><ul>
<li class="chapter" data-level="17.7.1" data-path="algebra.html"><a href="algebra.html#openblas"><i class="fa fa-check"></i><b>17.7.1</b> OpenBlas</a></li>
<li class="chapter" data-level="17.7.2" data-path="algebra.html"><a href="algebra.html#mkl"><i class="fa fa-check"></i><b>17.7.2</b> MKL</a></li>
</ul></li>
<li class="chapter" data-level="17.8" data-path="algebra.html"><a href="algebra.html#bibliographic-notes-15"><i class="fa fa-check"></i><b>17.8</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="17.9" data-path="algebra.html"><a href="algebra.html#practice-yourself-13"><i class="fa fa-check"></i><b>17.9</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="convex.html"><a href="convex.html"><i class="fa fa-check"></i><b>18</b> Convex Optimization</a><ul>
<li class="chapter" data-level="18.1" data-path="convex.html"><a href="convex.html#theoretical-backround"><i class="fa fa-check"></i><b>18.1</b> Theoretical Backround</a></li>
<li class="chapter" data-level="18.2" data-path="convex.html"><a href="convex.html#optimizing-with-r"><i class="fa fa-check"></i><b>18.2</b> Optimizing with R</a><ul>
<li class="chapter" data-level="18.2.1" data-path="convex.html"><a href="convex.html#the-optim-function"><i class="fa fa-check"></i><b>18.2.1</b> The optim Function</a></li>
<li class="chapter" data-level="18.2.2" data-path="convex.html"><a href="convex.html#the-nloptr-package"><i class="fa fa-check"></i><b>18.2.2</b> The nloptr Package</a></li>
<li class="chapter" data-level="18.2.3" data-path="convex.html"><a href="convex.html#minqa-package"><i class="fa fa-check"></i><b>18.2.3</b> minqa Package</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="convex.html"><a href="convex.html#bibliographic-notes-16"><i class="fa fa-check"></i><b>18.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="18.4" data-path="convex.html"><a href="convex.html#practice-yourself-14"><i class="fa fa-check"></i><b>18.4</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="rcpp.html"><a href="rcpp.html"><i class="fa fa-check"></i><b>19</b> RCpp</a><ul>
<li class="chapter" data-level="19.1" data-path="rcpp.html"><a href="rcpp.html#bibliographic-notes-17"><i class="fa fa-check"></i><b>19.1</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="19.2" data-path="rcpp.html"><a href="rcpp.html#practice-yourself-15"><i class="fa fa-check"></i><b>19.2</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="debugging.html"><a href="debugging.html"><i class="fa fa-check"></i><b>20</b> Debugging Tools</a><ul>
<li class="chapter" data-level="20.1" data-path="debugging.html"><a href="debugging.html#bibliographic-notes-18"><i class="fa fa-check"></i><b>20.1</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="20.2" data-path="debugging.html"><a href="debugging.html#practice-yourself-16"><i class="fa fa-check"></i><b>20.2</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="hadley.html"><a href="hadley.html"><i class="fa fa-check"></i><b>21</b> The Hadleyverse</a><ul>
<li class="chapter" data-level="21.1" data-path="hadley.html"><a href="hadley.html#readr"><i class="fa fa-check"></i><b>21.1</b> readr</a></li>
<li class="chapter" data-level="21.2" data-path="hadley.html"><a href="hadley.html#dplyr"><i class="fa fa-check"></i><b>21.2</b> dplyr</a></li>
<li class="chapter" data-level="21.3" data-path="hadley.html"><a href="hadley.html#tidyr"><i class="fa fa-check"></i><b>21.3</b> tidyr</a></li>
<li class="chapter" data-level="21.4" data-path="hadley.html"><a href="hadley.html#reshape2"><i class="fa fa-check"></i><b>21.4</b> reshape2</a></li>
<li class="chapter" data-level="21.5" data-path="hadley.html"><a href="hadley.html#stringr"><i class="fa fa-check"></i><b>21.5</b> stringr</a></li>
<li class="chapter" data-level="21.6" data-path="hadley.html"><a href="hadley.html#anytime"><i class="fa fa-check"></i><b>21.6</b> anytime</a></li>
<li class="chapter" data-level="21.7" data-path="hadley.html"><a href="hadley.html#biblipgraphic-notes"><i class="fa fa-check"></i><b>21.7</b> Biblipgraphic Notes</a></li>
<li class="chapter" data-level="21.8" data-path="hadley.html"><a href="hadley.html#practice-yourself-17"><i class="fa fa-check"></i><b>21.8</b> Practice Yourself</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>22</b> Causal Inferense</a><ul>
<li class="chapter" data-level="22.1" data-path="causality.html"><a href="causality.html#causal-inference-from-designed-experiments"><i class="fa fa-check"></i><b>22.1</b> Causal Inference From Designed Experiments</a><ul>
<li class="chapter" data-level="22.1.1" data-path="causality.html"><a href="causality.html#design-of-experiments"><i class="fa fa-check"></i><b>22.1.1</b> Design of Experiments</a></li>
<li class="chapter" data-level="22.1.2" data-path="causality.html"><a href="causality.html#randomized-inference"><i class="fa fa-check"></i><b>22.1.2</b> Randomized Inference</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="causality.html"><a href="causality.html#causal-inference-from-observational-data"><i class="fa fa-check"></i><b>22.2</b> Causal Inference from Observational Data</a><ul>
<li class="chapter" data-level="22.2.1" data-path="causality.html"><a href="causality.html#principal-stratification"><i class="fa fa-check"></i><b>22.2.1</b> Principal Stratification</a></li>
<li class="chapter" data-level="22.2.2" data-path="causality.html"><a href="causality.html#instrumental-variables"><i class="fa fa-check"></i><b>22.2.2</b> Instrumental Variables</a></li>
<li class="chapter" data-level="22.2.3" data-path="causality.html"><a href="causality.html#propensity-scores"><i class="fa fa-check"></i><b>22.2.3</b> Propensity Scores</a></li>
<li class="chapter" data-level="22.2.4" data-path="causality.html"><a href="causality.html#direct-lieklihood"><i class="fa fa-check"></i><b>22.2.4</b> Direct Lieklihood</a></li>
<li class="chapter" data-level="22.2.5" data-path="causality.html"><a href="causality.html#regression-discontinuity"><i class="fa fa-check"></i><b>22.2.5</b> Regression Discontinuity</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="causality.html"><a href="causality.html#bibliographic-notes-19"><i class="fa fa-check"></i><b>22.3</b> Bibliographic Notes</a></li>
<li class="chapter" data-level="22.4" data-path="causality.html"><a href="causality.html#practice-yourself-18"><i class="fa fa-check"></i><b>22.4</b> Practice Yourself</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R (BGU course)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lm" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Linear Models</h1>
<div id="problem-setup" class="section level2">
<h2><span class="header-section-number">6.1</span> Problem Setup</h2>

<div class="example">
<span id="exm:cap-experiment" class="example"><strong>Example 6.1  (Bottle Cap Production)  </strong></span>Consider a randomized experiment designed to study the effects of temperature and pressure on the diameter of manufactured a bottle cap.
</div>


<div class="example">
<span id="exm:rental" class="example"><strong>Example 6.2  (Rental Prices)  </strong></span>Consider the prediction of rental prices given an appartment’s attributes.
</div>

<p>Both examples require some statistical model, but they are very different.
The first is a <em>causal inference</em> problem: we want to design an intervention so that we need to recover the causal effect of temperature and pressure.
The second is a <a href="https://en.wikipedia.org/wiki/Prediction">prediction</a> problem, a.k.a. a <a href="https://en.wikipedia.org/wiki/Forecasting">forecasting</a> problem, in which we don’t care about the causal effects, we just want good predictions.</p>
<p>In this chapter we discuss the causal problem in Example <a href="lm.html#exm:cap-experiment">6.1</a>.
This means that when we assume a model, we assume it is the actual <em>data generating process</em>, i.e., we assume the <em>sampling distribution</em> is well specified.
In the econometric literature, these are the <a href="https://en.wikipedia.org/wiki/Structural_equation_modeling">structural equations</a>.
The second type of problems is discussed in the Supervised Learning Chapter <a href="supervised.html#supervised">10</a>.</p>
<p>Here are some more examples of the types of problems we are discussing.</p>

<div class="example">
<span id="exm:unnamed-chunk-146" class="example"><strong>Example 6.3  (Plant Growth)  </strong></span>Consider the treatment of various plants with various fertilizers to study the fertilizer’s effect on growth.
</div>


<div class="example">
<span id="exm:unnamed-chunk-147" class="example"><strong>Example 6.4  (Return to Education)  </strong></span>Consider the study of return to education by analyzing the incomes of individuals with different education years.
</div>


<div class="example">
<span id="exm:unnamed-chunk-148" class="example"><strong>Example 6.5  (Drug Effect)  </strong></span>Consider the study of the effect of a new drug for hemophilia, by analyzing the level of blood coagulation after the administration of various amounts of the new drug.
</div>

<p>Let’s present the linear model.
We assume that a response<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> variable is the sum of effects of some factors<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>.
Denoting the response variable by <span class="math inline">\(y\)</span>, the factors by <span class="math inline">\(x=(x_1,\dots,x_p)\)</span>, and the effects by <span class="math inline">\(\beta:=(\beta_1,\dots,\beta_p)\)</span> the linear model assumption implies that the expected response is the sum of the factors effects:</p>
<p><span class="math display" id="eq:linear-mean">\[\begin{align}
  E[y]=x_1 \beta_1 + \dots + x_p \beta_p = \sum_{j=1}^p x_j \beta_j = x&#39;\beta .
  \tag{6.1}
\end{align}\]</span>
Clearly, there may be other factors that affect the the caps’ diameters.
We thus introduce an error term<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>, denoted by <span class="math inline">\(\varepsilon\)</span>, to capture the effects of all unmodeled factors and measurement error<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a>.
The implied generative process of a sample of <span class="math inline">\(i=1,\dots,n\)</span> observations it thus
<span class="math display" id="eq:linear-observed">\[\begin{align}
  y_i = x_i&#39;\beta + \varepsilon_i = \sum_j x_{i,j} \beta_j + \varepsilon_i , i=1,\dots,n .
  \tag{6.2}
\end{align}\]</span>
or in matrix notation
<span class="math display" id="eq:linear-matrix">\[\begin{align}
  y = X \beta + \varepsilon .
  \tag{6.3}
\end{align}\]</span></p>
<p>Let’s demonstrate Eq.<a href="lm.html#eq:linear-observed">(6.2)</a>.
In our bottle-caps example [<a href="lm.html#exm:cap-experiment">6.1</a>], we may produce bottle caps at various temperatures.
We design an experiment where we produce bottle-caps at varying temperatures.
Let <span class="math inline">\(x_i\)</span> be the temperature at which bottle-cap <span class="math inline">\(i\)</span> was manufactured.
Let <span class="math inline">\(y_i\)</span> be its measured diameter.
By the linear model assumption, the expected diameter varies linearly with the temperature: <span class="math inline">\(\mathbb{E}[y_i]=\beta_0 + x_i \beta_1\)</span>.
This implies that <span class="math inline">\(\beta_1\)</span> is the (expected) change in diameter due to a unit change in temperature.</p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> In <a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean">Galton’s</a> classical regression problem, where we try to seek the relation between the heights of sons and fathers then <span class="math inline">\(p=1\)</span>, <span class="math inline">\(y_i\)</span> is the height of the <span class="math inline">\(i\)</span>’th father, and <span class="math inline">\(x_i\)</span> the height of the <span class="math inline">\(i\)</span>’th son.
This is a prediction problem, more than it is a causal-inference problem.
</div>

<p>There are many reasons linear models are very popular:</p>
<ol style="list-style-type: decimal">
<li><p>Before the computer age, these were pretty much the only models that could actually be computed<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>.
The whole Analysis of Variance (ANOVA) literature is an instance of linear models, that relies on sums of squares, which do not require a computer to work with.</p></li>
<li><p>For purposes of prediction, where the actual data generating process is not of primary importance, they are popular because they simply work.
Why is that?
They are simple so that they do not require a lot of data to be computed.
Put differently, they may be biased, but their variance is small enough to make them more accurate than other models.</p></li>
<li><p>For non continuous predictors, <strong>any</strong> functional relation can be cast as a linear model.</p></li>
<li><p>For the purpose of <em>screening</em>, where we only want to show the existence of an effect, and are less interested in the magnitude of that effect, a linear model is enough.</p></li>
<li><p>If the true generative relation is not linear, but smooth enough, then the linear function is a good approximation via Taylor’s theorem.</p></li>
</ol>
<p>There are still two matters we have to attend:
(i) How to estimate <span class="math inline">\(\beta\)</span>?
(ii) How to perform inference?</p>
<p>In the simplest linear models the estimation of <span class="math inline">\(\beta\)</span> is done using the method of least squares. A linear model with least squares estimation is known as Ordinary Least Squares (OLS).
The OLS problem:</p>
<p><span class="math display" id="eq:ols">\[\begin{align}
  \hat \beta:= argmin_\beta \{ \sum_i (y_i-x_i&#39;\beta)^2 \},
  \tag{6.4}
\end{align}\]</span>
and in matrix notation
<span class="math display" id="eq:ols-matrix">\[\begin{align}
  \hat \beta:= argmin_\beta \{ \Vert y-X\beta \Vert^2_2 \}.
  \tag{6.5}
\end{align}\]</span></p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Personally, I prefer the matrix notation because it is suggestive of the geometry of the problem.
The reader is referred to <span class="citation">Friedman, Hastie, and Tibshirani (<a href="#ref-friedman2001elements">2001</a>)</span>, Section 3.2, for more on the geometry of OLS.
</div>

<p>Different software suits, and even different R packages, solve Eq.<a href="lm.html#eq:ols">(6.4)</a> in different ways so that we skip the details of how exactly it is solved.
These are discussed in Chapters <a href="algebra.html#algebra">17</a> and <a href="convex.html#convex">18</a>.</p>
<p>The last matter we need to attend is how to do inference on <span class="math inline">\(\hat \beta\)</span>.
For that, we will need some assumptions on <span class="math inline">\(\varepsilon\)</span>.
A typical set of assumptions is the following:</p>
<ol style="list-style-type: decimal">
<li><strong>Independence</strong>: we assume <span class="math inline">\(\varepsilon_i\)</span> are independent of everything else.
Think of them as the measurement error of an instrument: it is independent of the measured value and of previous measurements.</li>
<li><strong>Centered</strong>: we assume that <span class="math inline">\(E[\varepsilon]=0\)</span>, meaning there is no systematic error, sometimes it called The “Linearity assumption”.</li>
<li><strong>Normality</strong>: we will typically assume that <span class="math inline">\(\varepsilon \sim \mathcal{N}(0,\sigma^2)\)</span>, but we will later see that this is not really required.</li>
</ol>
<p>We emphasize that these assumptions are only needed for inference on <span class="math inline">\(\hat \beta\)</span> and not for the estimation itself, which is done by the purely algorithmic framework of OLS.</p>
<p>Given the above assumptions, we can apply some probability theory and linear algebra to get the distribution of the estimation error:
<span class="math display" id="eq:ols-distribution">\[\begin{align}
  \hat \beta - \beta \sim \mathcal{N}(0, (X&#39;X)^{-1} \sigma^2).
  \tag{6.6}
\end{align}\]</span></p>
<p>The reason I am not too strict about the normality assumption above, is that Eq.<a href="lm.html#eq:ols-distribution">(6.6)</a> is approximately correct even if <span class="math inline">\(\varepsilon\)</span> is not normal, provided that there are many more observations than factors (<span class="math inline">\(n \gg p\)</span>).</p>
</div>
<div id="ols-estimation-in-r" class="section level2">
<h2><span class="header-section-number">6.2</span> OLS Estimation in R</h2>
<p>We are now ready to estimate some linear models with R.
We will use the <code>whiteside</code> data from the <strong>MASS</strong> package, recording the outside temperature and gas consumption, before and after an apartment’s insulation.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS) <span class="co"># load the package</span>
<span class="kw">library</span>(data.table) <span class="co"># for some data manipulations</span>
<span class="kw">data</span>(whiteside) <span class="co"># load the data</span>
<span class="kw">head</span>(whiteside) <span class="co"># inspect the data</span></code></pre>
<pre><code>##    Insul Temp Gas
## 1 Before -0.8 7.2
## 2 Before -0.7 6.9
## 3 Before  0.4 6.4
## 4 Before  2.5 6.0
## 5 Before  2.9 5.8
## 6 Before  3.2 5.8</code></pre>
<p>We do the OLS estimation on the pre-insulation data with <code>lm</code> function (acronym for Linear Model), possibly the most important function in R.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
whiteside &lt;-<span class="st"> </span><span class="kw">data.table</span>(whiteside)
lm<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(Gas<span class="op">~</span>Temp, <span class="dt">data=</span>whiteside[Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>]) <span class="co"># OLS estimation </span></code></pre>
<p>Things to note:</p>
<ul>
<li>We used the tilde syntax <code>Gas~Temp</code>, reading “gas as linear function of temperature”.</li>
<li>The <code>data</code> argument tells R where to look for the variables Gas and Temp.
We used <code>Insul=='Before'</code> to subset observations before the insulation.</li>
<li>The result is assigned to the object <code>lm.1</code>.</li>
</ul>
<p>Like any other language, spoken or programmable, there are many ways to say the same thing. Some more elegant than others…</p>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">y=</span>Gas, <span class="dt">x=</span>Temp, <span class="dt">data=</span>whiteside[whiteside<span class="op">$</span>Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>,]) 
lm<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">y=</span>whiteside[whiteside<span class="op">$</span>Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>,]<span class="op">$</span>Gas,<span class="dt">x=</span>whiteside[whiteside<span class="op">$</span>Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>,]<span class="op">$</span>Temp)  
lm<span class="fl">.1</span> &lt;-<span class="st"> </span>whiteside[whiteside<span class="op">$</span>Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>,] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">lm</span>(Gas<span class="op">~</span>Temp, <span class="dt">data=</span>.)</code></pre>
<p>The output is an object of class <code>lm</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(lm<span class="fl">.1</span>)</code></pre>
<pre><code>## [1] &quot;lm&quot;</code></pre>
<p>Objects of class <code>lm</code> are very complicated.
They store a lot of information which may be used for inference, plotting, etc.
The <code>str</code> function, short for “structure”, shows us the various elements of the object.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(lm<span class="fl">.1</span>)</code></pre>
<pre><code>## List of 12
##  $ coefficients : Named num [1:2] 6.854 -0.393
##   ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;Temp&quot;
##  $ residuals    : Named num [1:26] 0.0316 -0.2291 -0.2965 0.1293 0.0866 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:26] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ effects      : Named num [1:26] -24.2203 -5.6485 -0.2541 0.1463 0.0988 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:26] &quot;(Intercept)&quot; &quot;Temp&quot; &quot;&quot; &quot;&quot; ...
##  $ rank         : int 2
##  $ fitted.values: Named num [1:26] 7.17 7.13 6.7 5.87 5.71 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:26] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ assign       : int [1:2] 0 1
##  $ qr           :List of 5
##   ..$ qr   : num [1:26, 1:2] -5.099 0.196 0.196 0.196 0.196 ...
##   .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. ..$ : chr [1:26] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;Temp&quot;
##   .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1
##   ..$ qraux: num [1:2] 1.2 1.35
##   ..$ pivot: int [1:2] 1 2
##   ..$ tol  : num 1e-07
##   ..$ rank : int 2
##   ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot;
##  $ df.residual  : int 24
##  $ xlevels      : Named list()
##  $ call         : language lm(formula = Gas ~ Temp, data = whiteside[Insul == &quot;Before&quot;])
##  $ terms        :Classes &#39;terms&#39;, &#39;formula&#39;  language Gas ~ Temp
##   .. ..- attr(*, &quot;variables&quot;)= language list(Gas, Temp)
##   .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1
##   .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. .. ..$ : chr [1:2] &quot;Gas&quot; &quot;Temp&quot;
##   .. .. .. ..$ : chr &quot;Temp&quot;
##   .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;Temp&quot;
##   .. ..- attr(*, &quot;order&quot;)= int 1
##   .. ..- attr(*, &quot;intercept&quot;)= int 1
##   .. ..- attr(*, &quot;response&quot;)= int 1
##   .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; 
##   .. ..- attr(*, &quot;predvars&quot;)= language list(Gas, Temp)
##   .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot;
##   .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;Gas&quot; &quot;Temp&quot;
##  $ model        :&#39;data.frame&#39;:   26 obs. of  2 variables:
##   ..$ Gas : num [1:26] 7.2 6.9 6.4 6 5.8 5.8 5.6 4.7 5.8 5.2 ...
##   ..$ Temp: num [1:26] -0.8 -0.7 0.4 2.5 2.9 3.2 3.6 3.9 4.2 4.3 ...
##   ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39;  language Gas ~ Temp
##   .. .. ..- attr(*, &quot;variables&quot;)= language list(Gas, Temp)
##   .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1
##   .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. .. .. ..$ : chr [1:2] &quot;Gas&quot; &quot;Temp&quot;
##   .. .. .. .. ..$ : chr &quot;Temp&quot;
##   .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;Temp&quot;
##   .. .. ..- attr(*, &quot;order&quot;)= int 1
##   .. .. ..- attr(*, &quot;intercept&quot;)= int 1
##   .. .. ..- attr(*, &quot;response&quot;)= int 1
##   .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; 
##   .. .. ..- attr(*, &quot;predvars&quot;)= language list(Gas, Temp)
##   .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot;
##   .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;Gas&quot; &quot;Temp&quot;
##  - attr(*, &quot;class&quot;)= chr &quot;lm&quot;</code></pre>
<p>In RStudio it is particularly easy to extract objects. Just write <code>your.object$</code> and press <code>tab</code> after the <code>$</code> for auto-completion.</p>
<p>If we only want <span class="math inline">\(\hat \beta\)</span>, it can also be extracted with the <code>coef</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(lm<span class="fl">.1</span>)</code></pre>
<pre><code>## (Intercept)        Temp 
##   6.8538277  -0.3932388</code></pre>
<p>Things to note:</p>
<ul>
<li><p>R automatically adds an <code>(Intercept)</code> term.
This means we estimate <span class="math inline">\(Gas=\beta_0 + \beta_1 Temp + \varepsilon\)</span> and not <span class="math inline">\(Gas=\beta_1 Temp + \varepsilon\)</span>.
This makes sense because we are interested in the contribution of the temperature to the variability of the gas consumption about its <strong>mean</strong>, and not about zero.</p></li>
<li><p>The effect of temperature, i.e., <span class="math inline">\(\hat \beta_1\)</span>, is -0.39.
The negative sign means that the higher the temperature, the less gas is consumed.
The magnitude of the coefficient means that for a unit increase in the outside temperature, the gas consumption decreases by 0.39 units.</p></li>
</ul>
<p>We can use the <code>predict</code> function to make predictions, but we emphasize that if the purpose of the model is to make predictions, and not interpret coefficients, better skip to the Supervised Learning Chapter <a href="supervised.html#supervised">10</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Gas predictions (b0+b1*temperature) vs. actual Gas measurements, ideal slope should be 1.</span>
<span class="kw">plot</span>(<span class="kw">predict</span>(lm<span class="fl">.1</span>)<span class="op">~</span>whiteside[Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>,Gas])
<span class="co"># plots identity line (slope 1), lty=Line Type, 2 means dashed line.</span>
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-157-1.png" width="50%" /></p>
<p>The model seems to fit the data nicely.
A common measure of the goodness of fit is the <em>coefficient of determination</em>, more commonly known as the <span class="math inline">\(R^2\)</span>.</p>


<div class="definition">
<span id="def:unnamed-chunk-158" class="definition"><strong>Definition 6.1  (R2)  </strong></span>The coefficient of determination, denoted <span class="math inline">\(R^2\)</span>, is defined as
<span class="math display">\[\begin{align}
  R^2:= 1-\frac{\sum_i (y_i - \hat y_i)^2}{\sum_i (y_i - \bar y)^2},
\end{align}\]</span>
where <span class="math inline">\(\hat y_i\)</span> is the model’s prediction, <span class="math inline">\(\hat y_i = x_i \hat \beta\)</span>.
</div>

<p>It can be easily computed</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(magrittr)
R2 &lt;-<span class="st"> </span><span class="cf">function</span>(y, y.hat){
  numerator &lt;-<span class="st"> </span>(y<span class="op">-</span>y.hat)<span class="op">^</span><span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>sum
  denominator &lt;-<span class="st"> </span>(y<span class="op">-</span><span class="kw">mean</span>(y))<span class="op">^</span><span class="dv">2</span> <span class="op">%&gt;%</span><span class="st"> </span>sum
  <span class="dv">1</span><span class="op">-</span>numerator<span class="op">/</span>denominator
}
<span class="kw">R2</span>(<span class="dt">y=</span>whiteside[Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>,Gas], <span class="dt">y.hat=</span><span class="kw">predict</span>(lm<span class="fl">.1</span>))</code></pre>
<pre><code>## [1] 0.9438081</code></pre>
<p>This is a nice result implying that about <span class="math inline">\(94\%\)</span> of the variability in gas consumption can be attributed to changes in the outside temperature.</p>
<p>Obviously, R does provide the means to compute something as basic as <span class="math inline">\(R^2\)</span>, but I will let you find it for yourselves.</p>
</div>
<div id="inference" class="section level2">
<h2><span class="header-section-number">6.3</span> Inference</h2>
<p>To perform inference on <span class="math inline">\(\hat \beta\)</span>, in order to test hypotheses and construct confidence intervals, we need to quantify the uncertainly in the reported <span class="math inline">\(\hat \beta\)</span>.
This is exactly what Eq.<a href="lm.html#eq:ols-distribution">(6.6)</a> gives us.</p>
<p>Luckily, we don’t need to manipulate multivariate distributions manually, and everything we need is already implemented.
The most important function is <code>summary</code> which gives us an overview of the model’s fit.
We emphasize that fitting a model with <code>lm</code> is an assumption free algorithmic step.
Inference using <code>summary</code> is <strong>not</strong> assumption free, and requires the set of assumptions leading to Eq.<a href="lm.html#eq:ols-distribution">(6.6)</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm<span class="fl">.1</span>)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Gas ~ Temp, data = whiteside[Insul == &quot;Before&quot;])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.62020 -0.19947  0.06068  0.16770  0.59778 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.85383    0.11842   57.88   &lt;2e-16 ***
## Temp        -0.39324    0.01959  -20.08   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2813 on 24 degrees of freedom
## Multiple R-squared:  0.9438, Adjusted R-squared:  0.9415 
## F-statistic: 403.1 on 1 and 24 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Things to note:</p>
<ul>
<li>The estimated <span class="math inline">\(\hat \beta\)</span> is reported in the `Coefficients’ table, which has point estimates, standard errors, t-statistics, and the p-values of a two-sided hypothesis test for each coefficient <span class="math inline">\(H_{0,j}:\beta_j=0, j=1,\dots,p\)</span>.</li>
<li>The <span class="math inline">\(R^2\)</span> is reported at the bottom. The “Adjusted R-squared” is a variation that compensates for the model’s complexity.</li>
<li>The original call to <code>lm</code> is saved in the <code>Call</code> section.</li>
<li>Some summary statistics of the residuals (<span class="math inline">\(y_i-\hat y_i\)</span>) in the <code>Residuals</code> section.</li>
<li>The “residuals standard error”<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> is <span class="math inline">\(\sqrt{(n-p)^{-1} \sum_i (y_i-\hat y_i)^2}\)</span>. The denominator of this expression is the <em>degrees of freedom</em>, <span class="math inline">\(n-p\)</span>, which can be thought of as the hardness of the problem.</li>
</ul>
<p>As the name suggests, <code>summary</code> is merely a summary. The full <code>summary(lm.1)</code> object is a monstrous object.
Its various elements can be queried using <code>str(sumary(lm.1))</code>.</p>
<p>Can we check the assumptions required for inference?
Some.
Let’s start with the linearity assumption.
If we were wrong, and the data is not arranged about a linear line, the residuals will have some shape. We thus plot the residuals as a function of the predictor to diagnose shape.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># errors (epsilons) vs. temperature, should oscillate around zero.</span>
<span class="kw">plot</span>(<span class="kw">residuals</span>(lm<span class="fl">.1</span>)<span class="op">~</span>whiteside[Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>,Temp])
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-161-1.png" width="50%" /></p>
<p>I can’t say I see any shape.
Let’s fit a <strong>wrong</strong> model, just to see what “shape” means.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm.<span class="fl">1.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(Gas<span class="op">~</span><span class="kw">I</span>(Temp<span class="op">^</span><span class="dv">2</span>), <span class="dt">data=</span>whiteside[Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>,])
<span class="kw">plot</span>(<span class="kw">residuals</span>(lm.<span class="fl">1.1</span>)<span class="op">~</span>whiteside[Insul<span class="op">==</span><span class="st">&#39;Before&#39;</span>,Temp]); <span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-162-1.png" width="50%" /></p>
<p>Things to note:</p>
<ul>
<li>We used <code>I(Temp^2)</code> to specify the model <span class="math inline">\(Gas=\beta_0 + \beta_1 Temp^2+ \varepsilon\)</span>.</li>
<li>The residuals have a “belly”.
Because they are not a cloud around the linear trend, and we have the wrong model.</li>
</ul>
<p>To the next assumption.
We assumed <span class="math inline">\(\varepsilon_i\)</span> are independent of everything else.
The residuals, <span class="math inline">\(y_i-\hat y_i\)</span> can be thought of a sample of <span class="math inline">\(\varepsilon_i\)</span>.
When diagnosing the linearity assumption, we already saw their distribution does not vary with the <span class="math inline">\(x\)</span>’s, <code>Temp</code> in our case.
They may be correlated with themselves; a positive departure from the model, may be followed by a series of positive departures etc.
Diagnosing these <em>auto-correlations</em> is a real art, which is not part of our course.</p>
<p>The last assumption we required is normality.
As previously stated, if <span class="math inline">\(n \gg p\)</span>, this assumption can be relaxed.
If <span class="math inline">\(n\)</span> is in the order of <span class="math inline">\(p\)</span>, we need to verify this assumption.
My favorite tool for this task is the <em>qqplot</em>.
A qqplot compares the quantiles of the sample with the respective quantiles of the assumed distribution.
If quantiles align along a line, the assumed distribution is OK.
If quantiles depart from a line, then the assumed distribution does not fit the sample.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(<span class="kw">resid</span>(lm<span class="fl">.1</span>))</code></pre>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-163-1.png" width="50%" /></p>
<p>Things to note:</p>
<ul>
<li>The <code>qqnorm</code> function plots a qqplot against a normal distribution. For non-normal distributions try <code>qqplot</code>.</li>
<li><code>resid(lm.1)</code> extracts the residuals from the linear model, i.e., the vector of <span class="math inline">\(y_i-x_i&#39;\hat \beta\)</span>.</li>
</ul>
<p>Judging from the figure, the normality assumption is quite plausible.
Let’s try the same on a non-normal sample, namely a uniformly distributed sample, to see how that would look.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(<span class="kw">runif</span>(<span class="dv">100</span>))</code></pre>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-164-1.png" width="50%" /></p>
<div id="testing-a-hypothesis-on-a-single-coefficient" class="section level3">
<h3><span class="header-section-number">6.3.1</span> Testing a Hypothesis on a Single Coefficient</h3>
<p>The first inferential test we consider is a hypothesis test on a single coefficient.
In our gas example, we may want to test that the temperature has no effect on the gas consumption.
The answer for that is given immediately by <code>summary(lm.1)</code></p>
<pre class="sourceCode r"><code class="sourceCode r">summary.lm1 &lt;-<span class="st"> </span><span class="kw">summary</span>(lm<span class="fl">.1</span>)
coefs.lm1 &lt;-<span class="st"> </span>summary.lm1<span class="op">$</span>coefficients
coefs.lm1</code></pre>
<pre><code>##               Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)  6.8538277 0.11842341  57.87561 2.717533e-27
## Temp        -0.3932388 0.01958601 -20.07754 1.640469e-16</code></pre>
<p>We see that the p-value for <span class="math inline">\(H_{0,1}: \beta_1=0\)</span> against a two sided alternative is effectively 0 (row 2 column 4), so that <span class="math inline">\(\beta_1\)</span> is unlikely to be <span class="math inline">\(0\)</span> (the null hypothesis can be rejected).</p>
</div>
<div id="constructing-a-confidence-interval-on-a-single-coefficient" class="section level3">
<h3><span class="header-section-number">6.3.2</span> Constructing a Confidence Interval on a Single Coefficient</h3>
<p>Since the <code>summary</code> function gives us the standard errors of <span class="math inline">\(\hat \beta\)</span>, we can immediately compute <span class="math inline">\(\hat \beta_j \pm 2 \sqrt{Var[\hat \beta_j]}\)</span> to get ourselves a (roughly) <span class="math inline">\(95\%\)</span> confidence interval.
In our example the interval is</p>
<pre class="sourceCode r"><code class="sourceCode r">coefs.lm1[<span class="dv">2</span>,<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>coefs.lm1[<span class="dv">2</span>,<span class="dv">2</span>]</code></pre>
<pre><code>## [1] -0.4324108 -0.3540668</code></pre>
<p>Things to note:</p>
<ul>
<li>The function <code>confint(lm.1)</code> can calculate it. Sometimes it’s more simple to write 20 characters of code than finding a function that does it for us.</li>
</ul>
</div>
<div id="multiple-regression" class="section level3">
<h3><span class="header-section-number">6.3.3</span> Multiple Regression</h3>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> <em>Multiple regression</em> is not to be confused with <em>multivariate regression</em> discussed in Chapter <a href="multivariate.html#multivariate">9</a>.
</div>

<p>The <code>swiss</code> dataset encodes the fertility at each of Switzerland’s 47 French speaking provinces, along other socio-economic indicators. Let’s see if these are statistically related:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(swiss)</code></pre>
<pre><code>##              Fertility Agriculture Examination Education Catholic
## Courtelary        80.2        17.0          15        12     9.96
## Delemont          83.1        45.1           6         9    84.84
## Franches-Mnt      92.5        39.7           5         5    93.40
## Moutier           85.8        36.5          12         7    33.77
## Neuveville        76.9        43.5          17        15     5.16
## Porrentruy        76.1        35.3           9         7    90.57
##              Infant.Mortality
## Courtelary               22.2
## Delemont                 22.2
## Franches-Mnt             20.2
## Moutier                  20.3
## Neuveville               20.6
## Porrentruy               26.6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.5</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data=</span>swiss, Fertility<span class="op">~</span>Agriculture<span class="op">+</span>Examination<span class="op">+</span>Education<span class="op">+</span>Catholic<span class="op">+</span>Infant.Mortality)
<span class="kw">summary</span>(lm<span class="fl">.5</span>)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Fertility ~ Agriculture + Examination + Education + 
##     Catholic + Infant.Mortality, data = swiss)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.2743  -5.2617   0.5032   4.1198  15.3213 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      66.91518   10.70604   6.250 1.91e-07 ***
## Agriculture      -0.17211    0.07030  -2.448  0.01873 *  
## Examination      -0.25801    0.25388  -1.016  0.31546    
## Education        -0.87094    0.18303  -4.758 2.43e-05 ***
## Catholic          0.10412    0.03526   2.953  0.00519 ** 
## Infant.Mortality  1.07705    0.38172   2.822  0.00734 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.165 on 41 degrees of freedom
## Multiple R-squared:  0.7067, Adjusted R-squared:  0.671 
## F-statistic: 19.76 on 5 and 41 DF,  p-value: 5.594e-10</code></pre>
<p>Things to note:</p>
<ul>
<li>The <code>~</code> syntax allows to specify various predictors separated by the <code>+</code> operator.</li>
<li>The summary of the model now reports the estimated effect, i.e., the regression coefficient, of each of the variables.</li>
</ul>
<p>Clearly, naming each variable explicitly is a tedious task if there are many. The use of <code>Fertility~.</code> in the next example reads: “Fertility as a function of all other variables in the <code>swiss</code> data.frame”.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.5</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data=</span>swiss, Fertility<span class="op">~</span>.)
<span class="kw">summary</span>(lm<span class="fl">.5</span>)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Fertility ~ ., data = swiss)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.2743  -5.2617   0.5032   4.1198  15.3213 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      66.91518   10.70604   6.250 1.91e-07 ***
## Agriculture      -0.17211    0.07030  -2.448  0.01873 *  
## Examination      -0.25801    0.25388  -1.016  0.31546    
## Education        -0.87094    0.18303  -4.758 2.43e-05 ***
## Catholic          0.10412    0.03526   2.953  0.00519 ** 
## Infant.Mortality  1.07705    0.38172   2.822  0.00734 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.165 on 41 degrees of freedom
## Multiple R-squared:  0.7067, Adjusted R-squared:  0.671 
## F-statistic: 19.76 on 5 and 41 DF,  p-value: 5.594e-10</code></pre>
</div>
<div id="anova" class="section level3">
<h3><span class="header-section-number">6.3.4</span> ANOVA (*)</h3>
<p>Our next example<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> contains a hypothetical sample of <span class="math inline">\(60\)</span> participants who are divided into three stress reduction treatment groups (mental, physical, and medical) and three age groups groups.
The stress reduction values are represented on a scale that ranges from 1 to 10.
The values represent how effective the treatment programs were at reducing participant’s stress levels, with larger effects indicating higher effectiveness.</p>
<pre class="sourceCode r"><code class="sourceCode r">twoWay &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;data/dataset_anova_twoWay_comparisons.csv&#39;</span>)
<span class="kw">head</span>(twoWay)</code></pre>
<pre><code>##   Treatment   Age StressReduction
## 1    mental young              10
## 2    mental young               9
## 3    mental young               8
## 4    mental   mid               7
## 5    mental   mid               6
## 6    mental   mid               5</code></pre>
<p>How many observations per group?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(twoWay<span class="op">$</span>Treatment, twoWay<span class="op">$</span>Age)</code></pre>
<pre><code>##           
##            mid old young
##   medical    3   3     3
##   mental     3   3     3
##   physical   3   3     3</code></pre>
<p>Since we have two factorial predictors, this multiple regression is nothing but a <em>two way ANOVA</em>.
Let’s fit the model and inspect it.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(StressReduction<span class="op">~</span>.,<span class="dt">data=</span>twoWay)
<span class="kw">summary</span>(lm<span class="fl">.2</span>)</code></pre>
<pre><code>## 
## Call:
## lm(formula = StressReduction ~ ., data = twoWay)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##     -1     -1      0      1      1 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         4.0000     0.3892  10.276 7.34e-10 ***
## Treatmentmental     2.0000     0.4264   4.690 0.000112 ***
## Treatmentphysical   1.0000     0.4264   2.345 0.028444 *  
## Ageold             -3.0000     0.4264  -7.036 4.65e-07 ***
## Ageyoung            3.0000     0.4264   7.036 4.65e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9045 on 22 degrees of freedom
## Multiple R-squared:  0.9091, Adjusted R-squared:  0.8926 
## F-statistic:    55 on 4 and 22 DF,  p-value: 3.855e-11</code></pre>
<p>Things to note:</p>
<ul>
<li><p>The <code>StressReduction~.</code> syntax is read as “Stress reduction as a function of everything else”.</p></li>
<li><p>All the (main) effects and the intercept seem to be significant.</p></li>
<li><p>Mid age and medical treatment are missing, hence it is implied that they are the baseline, and this model accounts for the departure from this baseline.</p></li>
<li><p>The data has 2 factors, but the coefficients table has 4 predictors. This is because <code>lm</code> noticed that <code>Treatment</code> and <code>Age</code> are factors. Each level of each factor is thus encoded as a different (dummy) variable.
The numerical values of the factors are meaningless.
Instead, R has constructed a dummy variable for each level of each factor.
The names of the effect are a concatenation of the factor’s name, and its level.
You can inspect these dummy variables with the <code>model.matrix</code> command.</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">model.matrix</span>(lm<span class="fl">.2</span>) <span class="op">%&gt;%</span><span class="st"> </span>lattice<span class="op">::</span><span class="kw">levelplot</span>()</code></pre>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-173-1.png" width="50%" />
If you don’t want the default dummy coding, look at <code>?contrasts</code>.</p>
<p>If you are more familiar with the ANOVA literature, or that you don’t want the effects of each level separately, but rather, the effect of <strong>all</strong> the levels of each factor, use the <code>anova</code> command.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(lm<span class="fl">.2</span>)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: StressReduction
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Treatment  2     18   9.000      11 0.0004883 ***
## Age        2    162  81.000      99     1e-11 ***
## Residuals 22     18   0.818                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Things to note:</p>
<ul>
<li>The ANOVA table, unlike the <code>summary</code> function, tests if <strong>any</strong> of the levels of a factor has an effect, and not one level at a time.</li>
<li>The significance of each factor is computed using an F-test.</li>
<li>The degrees of freedom, encoding the number of levels of a factor, is given in the <code>Df</code> column.</li>
<li>The StressReduction seems to vary for different ages and treatments, since both factors are significant.</li>
</ul>
<p>If you are extremely more comfortable with the ANOVA literature, you could have replaced the <code>lm</code> command with the <code>aov</code> command all along.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm.<span class="fl">2.2</span> &lt;-<span class="st"> </span><span class="kw">aov</span>(StressReduction<span class="op">~</span>.,<span class="dt">data=</span>twoWay)
<span class="kw">class</span>(lm.<span class="fl">2.2</span>)</code></pre>
<pre><code>## [1] &quot;aov&quot; &quot;lm&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm.<span class="fl">2.2</span>)</code></pre>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Treatment    2     18    9.00      11 0.000488 ***
## Age          2    162   81.00      99    1e-11 ***
## Residuals   22     18    0.82                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Things to note:</p>
<ul>
<li>The <code>lm</code> function has been replaced with an <code>aov</code> function.</li>
<li>The output of <code>aov</code> is an <code>aov</code> class object, which extends the <code>lm</code> class.</li>
<li>The summary of an <code>aov</code> is not like the summary of an <code>lm</code> object, but rather, like an ANOVA table.</li>
</ul>
<p>As in any two-way ANOVA, we may want to ask if different age groups respond differently to different treatments.
In the statistical parlance, this is called an <em>interaction</em>, or more precisely, an <em>interaction of order 2</em>.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(StressReduction<span class="op">~</span>Treatment<span class="op">+</span>Age<span class="op">+</span>Treatment<span class="op">:</span>Age<span class="dv">-1</span>,<span class="dt">data=</span>twoWay)</code></pre>
<p>The syntax <code>StressReduction~Treatment+Age+Treatment:Age-1</code> tells R to include main effects of Treatment, Age, and their interactions. The -1 removes the intercept.
Here are other ways to specify the same model.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(StressReduction <span class="op">~</span><span class="st"> </span>Treatment <span class="op">*</span><span class="st"> </span>Age <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,<span class="dt">data=</span>twoWay)
lm<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(StressReduction<span class="op">~</span>(.)<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,<span class="dt">data=</span>twoWay)</code></pre>
<p>The syntax <code>Treatment * Age</code> means “main effects with second order interactions”.
The syntax <code>(.)^2</code> means “everything with second order interactions”, this time we don’t have I() as in the temperature example because here we want the second order interaction and not the square of each variable.</p>
<p>Let’s inspect the model</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm<span class="fl">.3</span>)</code></pre>
<pre><code>## 
## Call:
## lm(formula = StressReduction ~ Treatment + Age + Treatment:Age - 
##     1, data = twoWay)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##     -1     -1      0      1      1 
## 
## Coefficients:
##                              Estimate Std. Error t value Pr(&gt;|t|)    
## Treatmentmedical            4.000e+00  5.774e-01   6.928 1.78e-06 ***
## Treatmentmental             6.000e+00  5.774e-01  10.392 4.92e-09 ***
## Treatmentphysical           5.000e+00  5.774e-01   8.660 7.78e-08 ***
## Ageold                     -3.000e+00  8.165e-01  -3.674  0.00174 ** 
## Ageyoung                    3.000e+00  8.165e-01   3.674  0.00174 ** 
## Treatmentmental:Ageold      1.136e-16  1.155e+00   0.000  1.00000    
## Treatmentphysical:Ageold    2.392e-16  1.155e+00   0.000  1.00000    
## Treatmentmental:Ageyoung   -1.037e-15  1.155e+00   0.000  1.00000    
## Treatmentphysical:Ageyoung  2.564e-16  1.155e+00   0.000  1.00000    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1 on 18 degrees of freedom
## Multiple R-squared:  0.9794, Adjusted R-squared:  0.9691 
## F-statistic:    95 on 9 and 18 DF,  p-value: 2.556e-13</code></pre>
<p>Things to note:</p>
<ul>
<li>There are still <span class="math inline">\(5\)</span> main effects, but also <span class="math inline">\(4\)</span> interactions.
This is because when allowing a different average response for every <span class="math inline">\(Treatment*Age\)</span> combination, we are effectively estimating <span class="math inline">\(3*3=9\)</span> cell means, even if they are not parametrized as cell means, but rather as main effect and interactions.</li>
<li>The interactions do not seem to be significant.</li>
<li>The assumptions required for inference are clearly not met in this example, which is there just to demonstrate R’s capabilities.</li>
</ul>
<p>Asking if all the interactions are significant, is asking if the different age groups have the same response to different treatments.
Can we answer that based on the various interactions?
We might, but it is possible that no single interaction is significant, while the combination is.
To test for all the interactions together, we can simply check if the model without interactions is (significantly) better than a model with interactions. I.e., compare <code>lm.2</code> to <code>lm.3</code>.
This is done with the <code>anova</code> command.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(lm<span class="fl">.2</span>,lm<span class="fl">.3</span>, <span class="dt">test=</span><span class="st">&#39;F&#39;</span>)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: StressReduction ~ Treatment + Age
## Model 2: StressReduction ~ Treatment + Age + Treatment:Age - 1
##   Res.Df RSS Df  Sum of Sq  F Pr(&gt;F)
## 1     22  18                        
## 2     18  18  4 7.1054e-15  0      1</code></pre>
<p>We see that <code>lm.3</code> is <strong>not</strong> (significantly) better than <code>lm.2</code>, so that we can conclude that there are no interactions: different ages have the same response to different treatments.</p>
</div>
<div id="testing-a-hypothesis-on-a-single-contrast" class="section level3">
<h3><span class="header-section-number">6.3.5</span> Testing a Hypothesis on a Single Contrast (*)</h3>
<p>Returning to the model without interactions, <code>lm.2</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(<span class="kw">summary</span>(lm<span class="fl">.2</span>))</code></pre>
<pre><code>##                   Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)              4  0.3892495 10.276186 7.336391e-10
## Treatmentmental          2  0.4264014  4.690416 1.117774e-04
## Treatmentphysical        1  0.4264014  2.345208 2.844400e-02
## Ageold                  -3  0.4264014 -7.035624 4.647299e-07
## Ageyoung                 3  0.4264014  7.035624 4.647299e-07</code></pre>
<p>We see that the effect of the various treatments is rather similar.
It is possible that all treatments actually have the same effect.
Comparing the effects of factor levels is called a <em>contrast</em>.
Let’s test if the medical treatment, has in fact, the same effect as the physical treatment.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(multcomp)
my.contrast &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="dt">nrow =</span>  <span class="dv">1</span>)
lm<span class="fl">.4</span> &lt;-<span class="st"> </span><span class="kw">glht</span>(lm<span class="fl">.2</span>, <span class="dt">linfct=</span>my.contrast)
<span class="kw">summary</span>(lm<span class="fl">.4</span>)</code></pre>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Fit: lm(formula = StressReduction ~ ., data = twoWay)
## 
## Linear Hypotheses:
##        Estimate Std. Error t value Pr(&gt;|t|)    
## 1 == 0  -3.0000     0.7177   -4.18 0.000389 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<p>Things to note:</p>
<ul>
<li>A contrast is a linear function of the coefficients. In our example <span class="math inline">\(H_0:\beta_1-\beta_3=0\)</span>, which justifies the construction of <code>my.contrast</code>.</li>
<li>We used the <code>glht</code> function (generalized linear hypothesis test) from the package <strong>multcomp</strong>.</li>
<li>The contrast is significant, i.e., the effect of a medical treatment, is different than that of a physical treatment.</li>
</ul>
</div>
</div>
<div id="extra-diagnostics" class="section level2">
<h2><span class="header-section-number">6.4</span> Extra Diagnostics</h2>
<div id="diagnosing-heteroskedasticity" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Diagnosing Heteroskedasticity</h3>
<p>Textbook assumptions for inference on <span class="math inline">\(\hat \beta_{OLS}\)</span> include the <em>homoskedasticiy</em> assumption, i.e., <span class="math inline">\(Var[\varepsilon]\)</span> is fixed and independent of everyhting.
This comes from viewing <span class="math inline">\(\varepsilon\)</span> as a measurement error.
It may not be the case when viewing <span class="math inline">\(\varepsilon\)</span> as “all other effect not included in the model”.
In technical terms, homoskedastocity implies that <span class="math inline">\(Var[\varepsilon]\)</span> is a scaled identity matrix.
Heteroskedasticity means that <span class="math inline">\(Var[\varepsilon]\)</span> is a diagonal matrix.
Because a scaled identify matrix implies that the quantiles of a multivariate Gaussian are spheres, testing for heteroskedasticity is also known as a <em>Sphericity Test</em>.</p>
<p>Can we verify homoskedasticity, and do we need it?</p>
<p>To verify homoskedasticity we only need to look at the residuals of a model. If they seem to have the same variability for all <span class="math inline">\(x\)</span> we are clear.
If <span class="math inline">\(x\)</span> is multivariate, and we cannot visualise residuals, <span class="math inline">\(y_i-\hat y_i\)</span> as a function of <span class="math inline">\(x\)</span>, then visualising it as a function of <span class="math inline">\(\hat y_i\)</span> is also good.</p>
<p>Another way of dealing with heteroskedasticity is by estimating variances for groups of observations separately.
This is the <em>Cluster Robust Standard Errors</em> discussed in <a href="lme.html#cr-se">8.4.1</a>.</p>
<p>Can use perform a test to infer homoskedasticity?
In the frequentist hypotesis testing framework we can only reject homoskedasticity, not accept it.
In the <a href="https://en.wikipedia.org/wiki/Bayesian_inference">Bayesian hypotesis testing</a> framework we can indeed infer homoskedasticity, but one would have to defend his/her priors.</p>
<p>For some tests that detect heteroskedasticity see the <a href="https://cran.r-project.org/web/packages/olsrr/vignettes/heteroskedasticity.html">olsrr</a> package.
For an econometric flavored approach to the problem, see the <a href="https://cran.r-project.org/package=plm">plm</a> package, and its excellent <a href="https://cran.r-project.org/web/packages/plm/vignettes/plmPackage.html">vignette</a>.</p>
</div>
<div id="diagnosing-multicolinearity" class="section level3">
<h3><span class="header-section-number">6.4.2</span> Diagnosing Multicolinearity</h3>
<p>When designing an experiment (e.g. <a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial">RCTs</a>) we will assure treatments are “balanced”, so that one effect estimates are not correlated.
This is not always possible, especially not in observational studies.
If various variables capture the same effect, the certainty in the effect will “spread” over these variables.
Formally: the standard errros of effect estimates will increase.
Perhaps more importantly- causal inference with correlated predictors is very hard to interpret, because changes in outcome may be attibuted to any on of the (correlated) predictors.</p>
<p>We will eschew the complicated philosophical implication of causal infernece with correlated predictors, and merely refer the reader to the package <a href="https://cran.r-project.org/web/packages/olsrr/vignettes/regression_diagnostics.html">olsrr</a> for some popular tools to diagnose multicolinearity.</p>
</div>
</div>
<div id="bibliographic-notes-4" class="section level2">
<h2><span class="header-section-number">6.5</span> Bibliographic Notes</h2>
<p>Like any other topic in this book, you can consult <span class="citation">Venables and Ripley (<a href="#ref-venables2013modern">2013</a>)</span> for more on linear models.
For the theory of linear models, I like <span class="citation">Greene (<a href="#ref-greene2003econometric">2003</a>)</span>.</p>
</div>
<div id="practice-yourself-3" class="section level2">
<h2><span class="header-section-number">6.6</span> Practice Yourself</h2>
<ol style="list-style-type: decimal">
<li>Inspect women’s heights and weights with <code>?women</code>.
<ol style="list-style-type: decimal">
<li>What is the change in weight per unit change in height? Use the <code>lm</code> function.</li>
<li>Is the relation of height on weight significant? Use <code>summary</code>.</li>
<li>Plot the residuals of the linear model with <code>plot</code> and <code>resid</code>.</li>
<li>Plot the predictions of the model using <code>abline</code>.</li>
<li>Inspect the normality of residuals using <code>qqnorm</code>.</li>
<li>Inspect the design matrix using <code>model.matrix</code>.</li>
</ol></li>
<li>Write a function that takes an <code>lm</code> class object, and returns the confidence interval on the first coefficient. Apply it on the height and weight data.</li>
<li><p>Use the <code>ANOVA</code> function to test the significance of the effect of height.</p></li>
<li>Read about the “mtcars” dataset using <code>? mtcars</code>. Inspect the dependency of the fuel consumption (mpg) in the weight (wt) and the 1/4 mile time (qsec).
<ol style="list-style-type: decimal">
<li>Make a pairs scatter plot with <code>plot(mtcars[,c(&quot;mpg&quot;,&quot;wt&quot;,&quot;qsec&quot;)])</code>
Does the connection look linear?</li>
<li>Fit a multiple linear regression with <code>lm</code>. Call it <code>model1</code>.</li>
<li>Try to add the transmission (am) as independent variable. Let R know this is a categorical variable with <code>factor(am)</code>. Call it <code>model2</code>.</li>
<li>Compare the “Adjusted R-squared” measure of the two models (we can’t use the regular R2 to compare two models with a different number of variables).</li>
<li>Do the coefficients significant?</li>
<li>Inspect the normality of residuals and the linearity assumptions.</li>
<li>Now Inspect the hypothesis that the effect of weight is different between the transmission types with adding interaction to the model <code>wt*factor(am)</code>.</li>
<li>According to this model, what is the addition of one unit of weight in a manual transmission to the fuel consumption (-2.973-4.141=-7.11)?</li>
</ol></li>
</ol>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-friedman2001elements">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2001. <em>The Elements of Statistical Learning</em>. Vol. 1. Springer series in statistics Springer, Berlin.</p>
</div>
<div id="ref-greene2003econometric">
<p>Greene, William H. 2003. <em>Econometric Analysis</em>. Pearson Education India.</p>
</div>
<div id="ref-venables2013modern">
<p>Venables, William N, and Brian D Ripley. 2013. <em>Modern Applied Statistics with S-Plus</em>. Springer Science &amp; Business Media.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>The “response” is also known as the “dependent” variable in the statistical literature, or the “labels” in the machine learning literature.<a href="lm.html#fnref6" class="footnote-back">↩</a></p></li>
<li id="fn7"><p>The “factors” are also known as the “independent variable”, or “the design”, in the statistical literature, and the “features”, or “attributes” in the machine learning literature.<a href="lm.html#fnref7" class="footnote-back">↩</a></p></li>
<li id="fn8"><p>The “error term” is also known as the “noise”, or the “common causes of variability”.<a href="lm.html#fnref8" class="footnote-back">↩</a></p></li>
<li id="fn9"><p>You may philosophize if the measurement error is a mere instance of unmodeled factors or not, but this has no real implication for our purposes.<a href="lm.html#fnref9" class="footnote-back">↩</a></p></li>
<li id="fn10"><p>By “computed” we mean what statisticians call “fitted”, or “estimated”, and computer scientists call “learned”.<a href="lm.html#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>Sometimes known as the Root Mean Squared Error (RMSE).<a href="lm.html#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>The example is taken from <a href="http://rtutorialseries.blogspot.co.il/2011/02/r-tutorial-series-two-way-anova-with.html" class="uri">http://rtutorialseries.blogspot.co.il/2011/02/r-tutorial-series-two-way-anova-with.html</a><a href="lm.html#fnref12" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="eda.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/35-lm.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Rcourse.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
